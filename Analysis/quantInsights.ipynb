{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import openai\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDirectory = \"Dataset/ijcnlp_dailydialog\"\n",
    "textFile = dataDirectory + \"/dialogues_text.txt\"\n",
    "emotionFile = dataDirectory + \"/dialogues_emotion.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLinebyLine(filePath,maxLine=float('inf')):\n",
    "    currLine=0\n",
    "    with open(filePath, 'r') as file:\n",
    "    # Loop through each line in the file\n",
    "        for line in file:\n",
    "            if(currLine==maxLine):\n",
    "                return\n",
    "            # Process each line here\n",
    "            print(line.strip())  # Print the line after stripping whitespace (e.g., newline characters)\n",
    "            currLine+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractEmotionConversations(emotionFile, textFile, label):\n",
    "    conversationNumbers = set()\n",
    "    lineNumber = 0\n",
    "    count=0\n",
    "    with open(emotionFile, 'r') as file:\n",
    "    # Loop through each line in the file\n",
    "        for line in file:\n",
    "\n",
    "            if(label in line):\n",
    "                conversationNumbers.add(lineNumber)\n",
    "                count+=line.count(label)\n",
    "            lineNumber+=1\n",
    "    #print(len(conversationNumbers), count)\n",
    "    return conversationNumbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callGPTTesting(convMessages):\n",
    "    openai.api_type = \"azure\"\n",
    "    openai.api_base = \"REMOVED\"\n",
    "    openai.api_key = 'REMOVED'\n",
    "    openai.api_version = \"2023-05-15\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=\"GPT4\",\n",
    "        messages=convMessages\n",
    "    )\n",
    "\n",
    "    print(response['choices'][0]['message']['content'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tone of the message from Person 2 is not negative. They are simply expressing their preference for cigarettes over coffee. While they might be a little defensive, it doesn't reach the point of being 'extremely negative'.\n"
     ]
    }
   ],
   "source": [
    "conv = \"Person1: So Dick , how about getting some coffee for tonight ?\\nPerson2: Coffee ? I don ’ t honestly like that kind of stuff .\\nPerson1: Come on , you can at least try a little , besides your cigarette .\\nPerson 2: What ’ s wrong with that ? Cigarette is the thing I go crazy for .\"\n",
    "message = \"Person 2: What ’ s wrong with that ? Cigarette is the thing I go crazy for .\"\n",
    "prompt = \"Here is a conversation: \\n\" + conv + \"\\n\" + \"State if the tone/intent of the following message in the conversation above is negative (only if it is extremely negative) or not:\\n\" + message + '\\nFormat output like this: \"Y\" for yes and \"N\" for no.'\n",
    "messages = [\n",
    " {\"role\": \"user\", \"content\": prompt},\n",
    " {\"role\": \"assistant\",\"content\": \"N\"},\n",
    " {\"role\": \"user\", \"content\": \"Explain your answer.\"}\n",
    " ]\n",
    "\n",
    "callGPTTesting(messages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tone or intent of this message is neither extremely negative nor harmful. The speaker is just expressing his love for cigarettes and questioning why it should be a problem. It's a defensive statement, not a negative one.\n"
     ]
    }
   ],
   "source": [
    "conv = \"Person1: So Dick , how about getting some coffee for tonight ?\\nPerson2: Coffee ? I don ’ t honestly like that kind of stuff .\\nPerson1: Come on , you can at least try a little , besides your cigarette .\\nPerson 2: What ’ s wrong with that ? Cigarette is the thing I go crazy for .\"\n",
    "message = \"Person 2: What ’ s wrong with that ? Cigarette is the thing I go crazy for .\"\n",
    "prompt = \"Here is a conversation: \\n\" + conv + \"\\n\" + \"State if the tone/intent of the following message in the conversation above is negative (only if it is extremely negative) or not:\\n\" + message + '\\nFormat output like this: \"Y\" for yes and \"N\" for no.'\n",
    "messages = [\n",
    " {\"role\": \"user\", \"content\": prompt},\n",
    " {\"role\": \"assistant\",\"content\": \"N\"},\n",
    " {\"role\": \"user\", \"content\": \"Explain your answer.\"}\n",
    " ]\n",
    "\n",
    "callGPTTesting(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attachLabels(line):\n",
    "    rawConvo=line.split('__eou__')\n",
    "    proConvo = [item for item in rawConvo if item != '\\n']\n",
    "    for i in range(len(proConvo)):\n",
    "        if (i%2 == 1):\n",
    "            proConvo[i] = \"Person 2: \" + proConvo[i]\n",
    "        else:\n",
    "            proConvo[i] = \"Person 1: \" + proConvo[i]\n",
    "    return proConvo\n",
    "\n",
    "def prepareString(withLabels,currentIndex,history):\n",
    "    currString = ''\n",
    "    if(history == 0):\n",
    "        return withLabels[currentIndex]\n",
    "    elif(history ==1):\n",
    "        if(currentIndex==0):\n",
    "            return withLabels[0]\n",
    "        else:\n",
    "            currString += withLabels[currentIndex-1] + '\\n'\n",
    "            currString += withLabels[currentIndex] + '\\n'\n",
    "            return currString\n",
    "    elif history == 2:\n",
    "        for i in range(0,currentIndex+1):\n",
    "            currString = currString + withLabels[i] + \"'\\n\"\n",
    "        return currString\n",
    "    else:\n",
    "        raise ValueError(\"Invalid History:\", history)\n",
    "\n",
    "def preparePrompt(stringGPT, context,currLine,message):\n",
    "    finalPrompt = stringGPT\n",
    "    if(context):\n",
    "        finalPrompt = \"The topic of the following conversation is \" + getContext(currLine)+\".\\n\" + finalPrompt\n",
    "    else:\n",
    "        finalPrompt = \"Here is a conversation snippet:\" +\"\\n\" + finalPrompt\n",
    "\n",
    "    if ('@rukhshan@' in finalPrompt):\n",
    "        finalPrompt = finalPrompt.replace(\"@rukhshan@\",message)\n",
    "        #print(\"Final Prompt\", finalPrompt)\n",
    "    return finalPrompt\n",
    "\n",
    "def callGPT(finalPrompt):\n",
    "    openai.api_type = \"azure\"\n",
    "    #print(\"Prompt:\\n\", finalPrompt,'\\n\\n')\n",
    "    openai.api_base = \"REMOVED\"\n",
    "    openai.api_key = 'REMOVED'\n",
    "    openai.api_version = \"2023-05-15\"\n",
    "    '''\n",
    "    {\"role\":\"system\",\"content\":\"Assistant is a highly sensitive detector designed to help identify negative messages (even if slightly negative) in a conversation. A negative message may be perceived as angry, impolite, disrespectful, offensive, rude, inappropriate, or objectionable in any way by its recipient. Assistant will be called by the sender everytime they send a message to see if their message is even slightly negative or not.\"},\n",
    "            \n",
    "    {\"role\":\"user\", \"content\":'Here is a conversation:\\nPerson 1: So Dick , how about getting some coffee for tonight ? \\nPerson 2: Coffee ? I don ’ t honestly like that kind of stuff .\\nPerson 1: Come on , you can at least try a little , besides your cigarette . \\nPerson 2: What ’ s wrong with that ? Cigarette is the thing I go crazy for . \\nPerson 1: State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nPerson 2: What ’ s wrong with that ? Cigarette is the thing I go crazy for . \\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: \"Y\" if yes and \"N\" if no.'},\n",
    "    {\"role\":\"assistant\", \"content\":\"Y\"},\n",
    "    \n",
    "    {\"role\":\"user\", \"content\":\"Here is a conversation:\\nPerson 1: What happened to your car ?\\nPerson 2: A tow truck was towing my car and put all those dents in my car .\\nPerson 1: Are they going to pay you for the damages ?\\nPerson 2: They're saying it was already there .\\nPerson 1: What the hell . That doesn't make sense . What are you going to do ? \\nPerson 2: I have to go to court . A cop was there so he can prove that the damage wasn't there . \\nPerson 1: That sucks . I'd be pissed if that happened to me . \\nPerson 2: I got an estimate and it's four thousand dollars . \\nPerson 1: Oh my gosh . Damn ... screw the court , I would burn down their store .\\nPerson 2: State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nPerson 1: Oh my gosh . Damn ... screw the court , I would burn down their store .\\nPerson 2: Take into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\", \"content\":\"Y\"},\n",
    "\n",
    "\n",
    "    {\"role\":\"assistant\", \"content\":\"Here is a conversation:\\nPerson 1: Why don't you sit down and relax , darling ?\\nPerson 2: I don't want to .\\nPerson 1: Well , come over and talk to me then . \\nPerson 2: Certainly not .\\nPerson 1: May I turn on the TV then ?\\nPerson 2: Turn on the TV , for what ?\\nState if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\n Turn on the TV , for what ?\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\", \"content\":\"Y\"},\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    991\n",
    "    \"\\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ? \\nPerson#1  Yes . I'm OK . I just had a tumble . No big deal. \\nPerson#2  Good . You scared me . \\nPerson#1  Sorry . Can you please help me up ! I have trouble standing up by myself with the skis on . \\nPerson#2  Sure . Is this your first time skiing ? \\nPerson#1  Yes . I tried skiing on grass beforeNot very good at it , though . \"\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ?\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nAre you all right ?\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ? \\nPerson#1  Yes . I'm OK . I just had a tumble . No big deal. \\nPerson#2  Good . You scared me . \\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nGood . You scared me . \\n Take into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ? \\nPerson#1  Yes . I'm OK . I just had a tumble . No big deal. \\nPerson#2  Good . You scared me . \\nPerson#1  Sorry . Can you please help me up ! I have trouble standing up by myself with the skis on . \\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nSorry . Can you please help me up ! I have trouble standing up by myself with the skis on .\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "\n",
    "    '''\n",
    "    ''' \n",
    "    967\n",
    "\n",
    "    \"\\nPerson#1 What's the fare , please ?\\nPerson#2  Twenty dollars and sixty cents .\\nPerson#1  What ? You're overcharging me !\\nPerson#2  No way . Look . That's what the meter says .\\nPerson#1  Then something must be wrong with the meter .\"\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nWhat's the fare , please? \\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\nPerson#2  Twenty dollars and sixty cents .\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nTwenty dollars and sixty cents .\\n Take into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\nPerson#2  Twenty dollars and sixty cents .\\nPerson#1  What ? You're overcharging me !\\nPerson#2  No way . Look . That's what the meter says .\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nNo way . Look . That's what the meter says .\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "    \n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "    ''' \n",
    "    \n",
    "    number 2 example\n",
    "\n",
    "    {\"role\":\"user\", \"content\":\"Here is a conversation:\\nPerson 1: Why don't you sit down and relax , darling ?\\nPerson 2: I don't want to .\\nPerson 1: Well , come over and talk to me then . \\nPerson 2: Certainly not .\\nPerson 1: May I turn on the TV then ?\\nPerson 2: Turn on the TV , for what ?\\nState if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\n Turn on the TV , for what ?\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "            {\"role\":\"assistant\", \"content\":\"Y\"},\n",
    "    '''\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=\"GPT4\",\n",
    "        messages=[\n",
    "\n",
    "            {\"role\":\"user\", \"content\":'Here is a conversation:\\nPerson 1: So Dick , how about getting some coffee for tonight ? \\nPerson 2: Coffee ? I don ’ t honestly like that kind of stuff .\\nPerson 1: Come on , you can at least try a little , besides your cigarette . \\nPerson 2: What ’ s wrong with that ? Cigarette is the thing I go crazy for . \\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nPerson 2: What ’ s wrong with that ? Cigarette is the thing I go crazy for . \\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: \"Y\" if yes and \"N\" if no.'},\n",
    "            {\"role\":\"assistant\", \"content\":\"Y\"},\n",
    "\n",
    "            {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ?\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nAre you all right ?\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "            {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "            {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ? \\nPerson#1  Yes . I'm OK . I just had a tumble . No big deal. \\nPerson#2  Good . You scared me . \\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nGood . You scared me . \\n Take into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "            {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "            {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ? \\nPerson#1  Yes . I'm OK . I just had a tumble . No big deal. \\nPerson#2  Good . You scared me . \\nPerson#1  Sorry . Can you please help me up ! I have trouble standing up by myself with the skis on . \\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nSorry . Can you please help me up ! I have trouble standing up by myself with the skis on .\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "            {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "\n",
    "\n",
    "            {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nWhat's the fare , please? \\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "            {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "            {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\nPerson#2  Twenty dollars and sixty cents .\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nTwenty dollars and sixty cents .\\n Take into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "            {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "            {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\nPerson#2  Twenty dollars and sixty cents .\\nPerson#1  What ? You're overcharging me !\\nPerson#2  No way . Look . That's what the meter says .\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nNo way . Look . That's what the meter says .\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "            {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "        \n",
    "\n",
    "            \n",
    "            \n",
    "            {\"role\": \"user\", \"content\": finalPrompt}\n",
    "        ],\n",
    "        \n",
    "    )\n",
    "\n",
    "    if (\"N\" in response['choices'][0]['message']['content']):\n",
    "        return '0'\n",
    "    elif(\"Y\" in response['choices'][0]['message']['content']):\n",
    "        return '1'\n",
    "    elif(\"M\" in response['choices'][0]['message']['content']):\n",
    "        return '2'\n",
    "    else:\n",
    "        print(\"K Produced\",response['choices'][0]['message']['content'], \"\\nPrompt:\", finalPrompt)\n",
    "        return 'K'\n",
    "    \n",
    "def writeOutput(outputGPT, promptChosen,writeFilePath):\n",
    "\n",
    "    finalOutput = promptChosen.replace(\"\\n\",\"\") + \"\\n\" + outputGPT\n",
    "\n",
    "    # Open the file in write mode ('w')\n",
    "    # This will create the file if it doesn't exist or completely overwrite it if it does\n",
    "    with open(writeFilePath, 'w') as file:\n",
    "        file.write(finalOutput)\n",
    "\n",
    "    # The file is automatically closed when the 'with' block exits\n",
    "\n",
    "def getContext(currLineIndex):\n",
    "    with open(\"/Users/rukhshanharoon/Desktop/LLMChattingApp/Analysis/Dataset/ijcnlp_dailydialog/dialogues_topic.txt\", \"r\") as file:\n",
    "        # Read all lines into a list\n",
    "        lines = file.readlines()\n",
    "    contextNumber = lines[currLineIndex].replace(\"\\n\",\"\")\n",
    "    if(contextNumber==\"1\"):\n",
    "        return \"Ordinary Life\"\n",
    "    elif(contextNumber==\"2\"):\n",
    "        return \"School Life\"\n",
    "    elif(contextNumber==\"3\"):\n",
    "        return \"Culture & Education\"\n",
    "    elif(contextNumber==\"4\"):\n",
    "        return \"Attitude & Emotion\"\n",
    "    elif(contextNumber==\"5\"):\n",
    "        return \"Relationship\"\n",
    "    elif(contextNumber==\"6\"):\n",
    "        return \"Tourism\"\n",
    "    elif(contextNumber==\"7\"):\n",
    "        return \"Health\"\n",
    "    elif(contextNumber==\"8\"):\n",
    "        return \"Work\"\n",
    "    elif(contextNumber==\"9\"):\n",
    "        return \"Politics\"\n",
    "    elif(contextNumber==\"10\"):\n",
    "        return \"Finance\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid contextNumber:\", contextNumber)\n",
    "    \n",
    "def readSpecificConversations(filePath,conversationNumbers,promptChosen,writeFilePath, history=2,context=False, max=float('inf'), startFrom=0):\n",
    "    currLine=0\n",
    "    currOutput=''\n",
    "    currCount=0\n",
    "    reqCount=0\n",
    "    with open(filePath, 'r') as file:\n",
    "    # Loop through each line in the file\n",
    "        for line in file:\n",
    "            if(currLine in conversationNumbers and currLine>=startFrom):\n",
    "                convoPrinted = False\n",
    "                withLabels = attachLabels(line)\n",
    "                for i in range(len(withLabels)):\n",
    "                    convoGPT = prepareString(withLabels,i,history)\n",
    "                    finalPrompt = preparePrompt(convoGPT + promptChosen,context,currLine, withLabels[i])\n",
    "                    outputGPT=\"\"\n",
    "                    GPTdone = False\n",
    "                    while(GPTdone==False):\n",
    "                        try:  \n",
    "                            outputGPT = callGPT(finalPrompt)\n",
    "                            reqCount+=1\n",
    "                            print(\"Done\")\n",
    "                            GPTdone=True\n",
    "                        except Exception as e:\n",
    "                            print(\"Exception:\", e)\n",
    "                            #prints index\n",
    "                            #line number is index + 1\n",
    "                            #print(\"Conversation index: \", currLine)\n",
    "                            if('response was filtered due to the prompt triggering' in str(e)):\n",
    "                                #print(\"Skipped by GPT.\\n\" )    \n",
    "                                if(convoPrinted==False):\n",
    "                                    #print(\"Convo:\\n\", convoGPT)\n",
    "                                    convoPrinted = True\n",
    "                                outputGPT = \"S\"\n",
    "                                GPTdone=True\n",
    "                            else:\n",
    "                                #print(\"Sleeping for 8.\")\n",
    "                                time.sleep(8)\n",
    "                    currOutput = currOutput +\" \" + outputGPT\n",
    "                #currOutput = currOutput + \"\\n\"\n",
    "                currCount+=1\n",
    "                if(currCount==max):\n",
    "                    writeOutput(currOutput, promptChosen,writeFilePath)\n",
    "                    #print(\"Total Requests:\", reqCount)\n",
    "                    return '\\n'.join([line.lstrip() for line in currOutput.splitlines()])\n",
    "                else:\n",
    "                    currOutput = currOutput + \"\\n\"\n",
    "            \n",
    "            currLine+=1\n",
    "    writeOutput(currOutput, promptChosen,writeFilePath)\n",
    "    #print(\"Total Requests:\", reqCount)\n",
    "    return '\\n'.join([line.lstrip() for line in currOutput.splitlines()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractLabels(emotionFile, label, max=float('inf')):\n",
    "    conversations =\"\"\n",
    "    lineNumber = 0\n",
    "\n",
    "    with open(emotionFile, 'r') as file:\n",
    "    # Loop through each line in the file\n",
    "        for line in file:\n",
    "            if(lineNumber == max):\n",
    "                return conversations\n",
    "\n",
    "            if(label in line):\n",
    "                newLine=\"\"\n",
    "                for i in range (len(line)):\n",
    "                    if((line[i] != \" \") and (line[i] != \"\\n\") and (line[i] != \"1\") and (line[i] != \"2\")):\n",
    "                        newLine += '0'\n",
    "                    else:\n",
    "                        newLine +=line[i]\n",
    "                conversations += newLine\n",
    "                lineNumber+=1\n",
    "\n",
    "        \n",
    "    #print(len(conversationNumbers), count)\n",
    "    return conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeRealLabels(labels, name):\n",
    "    with open(name, 'w') as file:\n",
    "        file.write(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(realLabels, genLabelsName):\n",
    "\n",
    "    processedRealLabels=\"\"\n",
    "    processedGenLabels=\"\"\n",
    "    index=[]\n",
    "    selectedIndex=[]\n",
    "    indexCount=0\n",
    "    n=0\n",
    "    \n",
    "    \n",
    "    firstLine = False\n",
    "    with open(genLabelsName, 'r') as file:\n",
    "        for line in file:\n",
    "            #print(\"Line at index \", indexCount,\"  \", line  )\n",
    "            # Skip first line\n",
    "            if(firstLine==False):\n",
    "                firstLine=True\n",
    "            elif 'S' not in line and 'K' not in line:\n",
    "                # If it doesn't contain \"S\", add the line to the processed content\n",
    "                cleanedLine = line.replace(\"\\n\", \"\").replace(\" \", \"\")\n",
    "                processedGenLabels += cleanedLine\n",
    "                selectedIndex.append(indexCount)\n",
    "                indexCount+=1\n",
    "                n+=1\n",
    "                \n",
    "            else:\n",
    "                #indexes of lines that contain S in REAL file\n",
    "                #print(\"Contains N!\")\n",
    "                index.append(indexCount)\n",
    "                indexCount+=1\n",
    "    \n",
    "    #print(selectedIndex)\n",
    "    indexCount=0\n",
    "    lineCount=0\n",
    "    with open(realLabels, 'r') as file:\n",
    "        for line in file:\n",
    "            lineCount+=1\n",
    "            if ((indexCount in index) or not(indexCount in selectedIndex)):\n",
    "                indexCount+=1\n",
    "            else:\n",
    "                indexCount+=1\n",
    "                cleanedLine = line.replace(\"\\n\", \"\").replace(\" \", \"\")\n",
    "                for char in cleanedLine:\n",
    "                    if(char =='1'):\n",
    "                        processedRealLabels += char\n",
    "                    else:\n",
    "                        processedRealLabels += '0'            \n",
    "    #print(processedRealLabels)\n",
    "    #print(\"Original Val of n,\",n)\n",
    "    return processedRealLabels, processedGenLabels,n\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpretng Precision\n",
    "#Precision is a measure of true positives / true positives + false positives\n",
    "#Shows how many positives are true from the set of all elements marked as positive by the model\n",
    "#TP/(TP+FP)\n",
    "#5/(5+5) -> 0.5 means that out of all elements it marked as positive, only half were actually positive and the rest were negative. the higher the value, higher the precision\n",
    "#higher the precision, higher the quality of positive predictions\n",
    "\n",
    "#Interpreting Recall\n",
    "#shows the proportion of all true positives that the model was able to classify as positive \n",
    "#TP/(TP + FN)\n",
    "#5/(5+5) -> shows that it was only able to detect 5 out of the 10 true positive elements.\n",
    "#higher the recall, higher the sensitivity\n",
    "def PRFA(angryOnlyRealLabels, angryOnlyGenLabels,n, promptNumber, ITConvos, Prompt,History, Context, pathFinalOutput):\n",
    "    # Initialize counters for True Positives (TP), False Positives (FP), True Negatives (TN), False Negatives (FN)\n",
    "    TP = FP = TN = FN = 0\n",
    "    '''\n",
    "    # Calculate TP, FP, TN, FN\n",
    "    for true_label, predicted_label in zip(angryOnlyRealLabels, angryOnlyGenLabels):\n",
    "        if (true_label == '1' and (predicted_label == '1' or predicted_label == \"2\")):\n",
    "            TP += 1\n",
    "        elif true_label == '0' and predicted_label == '1':\n",
    "            FP += 1\n",
    "        elif true_label == '0' and (predicted_label == '0' or predicted_label== \"2\"):\n",
    "            TN += 1\n",
    "        elif true_label == '1' and predicted_label == '0':\n",
    "            FN += 1\n",
    "    '''\n",
    "    for true_label, predicted_label in zip(angryOnlyRealLabels, angryOnlyGenLabels):\n",
    "        if (true_label == '1' and predicted_label == '1'):\n",
    "            TP += 1\n",
    "        elif true_label == '0' and predicted_label == '1':\n",
    "            FP += 1\n",
    "        elif true_label == '0' and predicted_label == '0':\n",
    "            TN += 1\n",
    "        elif true_label == '1' and predicted_label == '0':\n",
    "            FN += 1\n",
    "    \n",
    "    # Calculate Precision, Recall, F1 Score, and Accuracy\n",
    "    try:\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    except Exception as e:\n",
    "        precision =9999999\n",
    "        recall = 9999999\n",
    "        f1_score =9999999\n",
    "        accuracy = 9999999\n",
    "        print(str(e))\n",
    "\n",
    "    if(Context):\n",
    "        Context='Y'\n",
    "    else:\n",
    "        Context='N'\n",
    "        \n",
    "    dataset = {\n",
    "    \"#Prompt\": promptNumber,\n",
    "    \"#ITConvos\": ITConvos,\n",
    "    \"Prompt\": Prompt,\n",
    "    \"History(n)\": History,\n",
    "    \"Context\":Context,\n",
    "    \"Precision\": precision,\n",
    "    \"Recall\": recall,\n",
    "    \"F1\": f1_score,\n",
    "    \"Accuracy\": accuracy,\n",
    "    \"FP\": FP,\n",
    "    \"FN\": FN,\n",
    "    \"TP\": TP,\n",
    "    \"TN\": TN,\n",
    "    \"#FTMessages\": FP + FN + TP + TN,\n",
    "    \"#FTConvos\": n\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame.from_dict([dataset])\n",
    "        # print(\"Precision:\", precision)\n",
    "        # print(\"Recall:\", recall)\n",
    "        # print(\"F1 Score:\", f1_score)\n",
    "        # print(\"Accuracy:\", accuracy)\n",
    "        # print(\"FP\", FP)\n",
    "        # print(\"FN\", FN)\n",
    "        # print(\"TP\",TP)\n",
    "        # print(\"TN\",TN)\n",
    "        # print(\"Total:\", FP+FN+TP+TN)\n",
    "        # print(\"Total Convos:\",n)\n",
    "\n",
    "    if not os.path.isfile(pathFinalOutput):\n",
    "    # If the file doesn't exist, create it with the DataFrame and include the column headers\n",
    "        df.to_csv(pathFinalOutput, index=False)\n",
    "    else:\n",
    "        # If the file exists, append the DataFrame to it without writing column headers\n",
    "        df.to_csv(pathFinalOutput, mode='a', header=False, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation indexes with at least 1 angry emotion:\n",
      " {1, 2, 10251, 12301, 15, 32, 2084, 4132, 4134, 10281, 4143, 12337, 2100, 2101, 2102, 2106, 2111, 2113, 4161, 4165, 6214, 76, 2126, 4179, 4182, 8278, 8283, 2140, 4188, 95, 96, 97, 2148, 4196, 12395, 4205, 4208, 4211, 12403, 2168, 4216, 4217, 12408, 4220, 8318, 8321, 4227, 4228, 8324, 4231, 136, 12425, 4237, 4243, 10388, 10389, 10390, 10392, 10393, 155, 4251, 157, 10395, 10396, 4256, 4257, 4259, 4263, 6139, 2218, 10413, 12653, 2223, 2224, 4273, 178, 10415, 2228, 10416, 2230, 4278, 4280, 186, 4283, 2236, 2237, 10429, 2239, 2241, 2243, 4308, 2262, 4310, 4314, 222, 4320, 4321, 2275, 4327, 2280, 8428, 2285, 12530, 4348, 2302, 4354, 8452, 4362, 2324, 10517, 4377, 4379, 4387, 295, 296, 6440, 8487, 300, 4398, 306, 311, 8503, 4414, 10564, 2374, 327, 4423, 8521, 4426, 4427, 2380, 8522, 8526, 2383, 2384, 4431, 338, 2387, 8534, 2391, 351, 2402, 4451, 12642, 357, 364, 2413, 4460, 2415, 368, 2416, 370, 4465, 12284, 12652, 4470, 12656, 4472, 2427, 380, 4477, 12674, 2435, 12677, 12678, 12679, 392, 12680, 12681, 4491, 4495, 2451, 4500, 4502, 408, 8600, 4506, 4512, 417, 4515, 2471, 4521, 2474, 2476, 2478, 4526, 4529, 4532, 4533, 4534, 2489, 6588, 4544, 6593, 8645, 4550, 2505, 4553, 6601, 2509, 2510, 6605, 8656, 4562, 2515, 2518, 4567, 6615, 2523, 2524, 2525, 2526, 4576, 4580, 4581, 2534, 4582, 4583, 10727, 490, 4590, 4592, 4596, 8692, 4598, 6652, 4606, 519, 4615, 4616, 6666, 8715, 4621, 4624, 529, 4625, 8726, 4633, 6684, 8738, 4648, 4662, 4663, 2617, 576, 4674, 4680, 6732, 8792, 2651, 2654, 2657, 2661, 6757, 4719, 4720, 4722, 6776, 636, 2687, 4743, 8840, 8843, 10895, 8849, 4756, 8853, 4759, 4760, 4761, 4762, 10908, 8864, 4769, 4770, 2728, 4776, 4777, 4778, 4780, 4782, 4783, 4787, 4794, 10938, 4800, 4801, 2758, 4816, 13017, 8922, 4829, 2785, 8936, 8939, 2811, 2816, 769, 8963, 6922, 789, 13088, 814, 9019, 2887, 9031, 9033, 4949, 2902, 4951, 2924, 2937, 4993, 11151, 7059, 917, 935, 2992, 3006, 7105, 9154, 9158, 967, 3017, 9166, 3023, 9168, 9170, 3030, 9179, 991, 3042, 3050, 11256, 3073, 3077, 3078, 3084, 3085, 3087, 1042, 3091, 3092, 3095, 3100, 3102, 3105, 3106, 3109, 3111, 5159, 3113, 3116, 3118, 3120, 5185, 5195, 3156, 3157, 5216, 5228, 9328, 9332, 9334, 3215, 1176, 9376, 1194, 3249, 3256, 3259, 7356, 5310, 3263, 3266, 9414, 11463, 3286, 1245, 5357, 3323, 3327, 1301, 9502, 1319, 5431, 9538, 1347, 1348, 11597, 1364, 11605, 1377, 7521, 5477, 3445, 11637, 11646, 11647, 11661, 1423, 11666, 1428, 1429, 11672, 1443, 3493, 3495, 3499, 7596, 3504, 11700, 1483, 7629, 7637, 1494, 7639, 1504, 1525, 1530, 3579, 5628, 3582, 1535, 3586, 1539, 1542, 1543, 7686, 11783, 9739, 1595, 11837, 1598, 11851, 11854, 11856, 11858, 11863, 11865, 1654, 9858, 1668, 11909, 9867, 9874, 9877, 5794, 5795, 7844, 7852, 3758, 5809, 3764, 3769, 7866, 3775, 7875, 9927, 1741, 5843, 1752, 1779, 12020, 1791, 5889, 1799, 9994, 9999, 3862, 12067, 1828, 5936, 12083, 5958, 12105, 12106, 5971, 5982, 10092, 1922, 12163, 10121, 10122, 10124, 10127, 1940, 12191, 10566, 12206, 1969, 1977, 8123, 10175, 12235, 10190, 1999, 12240, 6107, 12617, 2026, 2029, 10224, 2033, 12280, 12282, 2043, 6140}\n"
     ]
    }
   ],
   "source": [
    "#conversations with at least one message labeled as angry\n",
    "angryConversations = extractEmotionConversations(emotionFile,textFile,'1')\n",
    "print(\"Conversation indexes with at least 1 angry emotion:\\n\",angryConversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = extractLabels(emotionFile, '1', 40)\n",
    "writeRealLabels(labels, \"angryReal40.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = extractLabels(emotionFile, '1', 40)\n",
    "writeRealLabels(labels, \"angrydisgustReal40.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    '\\nState if the tone/intent of the last message in the conversation above is negative or not this format: \"Y\" for yes and \"N\" for no.',\n",
    "    '\\nState if the tone/intent of the last message in the conversation above is negative (even if it is slightly negative) or not. Format output like this: \"Y\" for yes and \"N\" for no.',\n",
    "    '\\nState if the tone/intent of the last message in the conversation above is negative (only those which are extremely negative) or not. Format output like this: \"Y\" for yes and \"N\" for no.',\n",
    "    '\\nState if the tone/intent of the last message in the conversation above is extremely negative, clearly not negative, or maybe negative. Format output like this: \"Y\" for Extremely Negative and \"N\" for Clearly Not Negative and \"M\" for Maybe Negative.',\n",
    "    '\\nWould the last message in the conversation above be perceived as blunt/negative/offensive by its recipient? Format your output like this: \"Y\" if Yes and \"N\" if No and \"M\" if Maybe.',\n",
    "    '\\nWould the last message in the conversation above be perceived as blunt/negative/offensive by its recipient? Format your output like this: \"Y\" if Yes and \"N\" if No.'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prompt 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'State if the tone/intent of the last message in the conversation above is negative (even if it is slightly negative) or not. Format output like this: \"Y\" for yes and \"N\" for no.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History: 0\n",
    "Context: Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsGPT = readSpecificConversations(textFile,angryConversations,prompt,\"output96/output-10-1-Y.txt\",history =1, context=True, max=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths: 264 264\n",
      "\n",
      "\n",
      "**Stats**\n",
      "\n",
      "\n",
      "Precision: 0.44871794871794873\n",
      "Recall: 0.7291666666666666\n",
      "F1 Score: 0.5555555555555556\n",
      "Accuracy: 0.7878787878787878\n",
      "FP 43\n",
      "FN 13\n",
      "TP 35\n",
      "TN 173\n",
      "Total: 264\n",
      "Total Convos: 37\n"
     ]
    }
   ],
   "source": [
    "#reads output file\n",
    "#records labels AND indexes for all convos that were NOT skipped\n",
    "#reads angryReal40.txt\n",
    "#extracts labels for all convos that were NOT skipped by matching their indexes with the indexes collected previously\n",
    "angryOnlyRealLabels, angryOnlyGenLabels,n = processData('angryReal40.txt', 'output10/output-10-0-Y.txt')\n",
    "print(\"Lengths:\",len(angryOnlyRealLabels),len(angryOnlyGenLabels))\n",
    "print(\"\\n\\n**Stats**\\n\\n\")\n",
    "PRFA(angryOnlyRealLabels,angryOnlyGenLabels,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History: 1\n",
    "Context: Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 1:  And after that ? \n",
      "Person 2:  After that , we'll let you decide if you still want a murder , I mean motorcycle . \n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 1:  What ? He can't do this to you . \n",
      "Person 2:  Well , he did it anyway . Then he came into my room and shot all his shit blah blah blah ... you know . \n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 1:  Oh my gosh . Damn ... screw the court , I would burn down their store . \n",
      "Person 2:  We'll see what happens after court . \n",
      "\n",
      "Total Requests: 294\n"
     ]
    }
   ],
   "source": [
    "labelsGPT = readSpecificConversations(textFile,angryConversations,prompt,\"output10/output-10-1-Y.txt\",history =1, context=True, max=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths: 264 264\n",
      "\n",
      "\n",
      "**Stats**\n",
      "\n",
      "\n",
      "Precision: 0.47435897435897434\n",
      "Recall: 0.7708333333333334\n",
      "F1 Score: 0.5873015873015872\n",
      "Accuracy: 0.803030303030303\n",
      "FP 41\n",
      "FN 11\n",
      "TP 37\n",
      "TN 175\n",
      "Total: 264\n",
      "Total Convos: 37\n"
     ]
    }
   ],
   "source": [
    "#reads output file\n",
    "#records labels AND indexes for all convos that were NOT skipped\n",
    "#reads angryReal40.txt\n",
    "#extracts labels for all convos that were NOT skipped by matching their indexes with the indexes collected previously\n",
    "angryOnlyRealLabels, angryOnlyGenLabels,n = processData('angryReal40.txt', 'output10/output-10-1-Y.txt')\n",
    "print(\"Lengths:\",len(angryOnlyRealLabels),len(angryOnlyGenLabels))\n",
    "print(\"\\n\\n**Stats**\\n\\n\")\n",
    "PRFA(angryOnlyRealLabels,angryOnlyGenLabels,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History: 2\n",
    "Context: Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 1: Mom , I want to get a motorcycle . Is that all right with you ? '\n",
      "Person 2:  You mean a murder cycle ? Did you know more cyclists die in accidents than motorists ? '\n",
      "Person 1:  Mom ! I'll wear a helmet and I'll drive sane . I promise . '\n",
      "Person 2:  I'll tell you what . You can get a motorcycle on one condition . '\n",
      "Person 1:  What's that ? '\n",
      "Person 2:  You spend two weeks with dad in his ambulance as an EMT trainee and volunteer at the emergency room for one month . '\n",
      "Person 1:  And after that ? '\n",
      "Person 2:  After that , we'll let you decide if you still want a murder , I mean motorcycle . '\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 1: What's up ? You sound a little down in dumps . '\n",
      "Person 2:  I quarreled with my roommate last night . He is really stubborn . '\n",
      "Person 1:  Calm down ! Shouting won ’ t help ? '\n",
      "Person 2:  He is really outrageous . '\n",
      "Person 1:  What happened ? '\n",
      "Person 2:  I went back home last night . You know tired as a dog , so I took a quick shower and went to bed . I couldn't fall asleep , because Brian was there in the living room , playing his stupid stereo so loud . I kindly told him to turn that down a little bit . He shouted at me . '\n",
      "Person 1:  What ? He can't do this to you . '\n",
      "Person 2:  Well , he did it anyway . Then he came into my room and shot all his shit blah blah blah ... you know . '\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Total Requests: 288\n"
     ]
    }
   ],
   "source": [
    "labelsGPT = readSpecificConversations(textFile,angryConversations,prompt,\"output10/output-10-2-Y.txt\",history =2, context=True, max=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths: 274 274\n",
      "\n",
      "\n",
      "**Stats**\n",
      "\n",
      "\n",
      "Precision: 0.42857142857142855\n",
      "Recall: 0.78\n",
      "F1 Score: 0.5531914893617021\n",
      "Accuracy: 0.7700729927007299\n",
      "FP 52\n",
      "FN 11\n",
      "TP 39\n",
      "TN 172\n",
      "Total: 274\n",
      "Total Convos: 38\n"
     ]
    }
   ],
   "source": [
    "#reads output file\n",
    "#records labels AND indexes for all convos that were NOT skipped\n",
    "#reads angryReal40.txt\n",
    "#extracts labels for all convos that were NOT skipped by matching their indexes with the indexes collected previously\n",
    "angryOnlyRealLabels, angryOnlyGenLabels,n = processData('angryReal40.txt', 'output10/output-10-2-Y.txt')\n",
    "print(\"Lengths:\",len(angryOnlyRealLabels),len(angryOnlyGenLabels))\n",
    "print(\"\\n\\n**Stats**\\n\\n\")\n",
    "PRFA(angryOnlyRealLabels,angryOnlyGenLabels,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History: 0\n",
    "Context: N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 2:  After that , we'll let you decide if you still want a murder , I mean motorcycle . \n",
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 2:  Well , he did it anyway . Then he came into my room and shot all his shit blah blah blah ... you know . \n",
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 1:  Oh my gosh . Damn ... screw the court , I would burn down their store . \n",
      "Total Requests: 295\n"
     ]
    }
   ],
   "source": [
    "labelsGPT = readSpecificConversations(textFile,angryConversations,prompt,\"output10/output-10-0-N.txt\",history =0, context=False, max=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths: 264 264\n",
      "\n",
      "\n",
      "**Stats**\n",
      "\n",
      "\n",
      "Precision: 0.4375\n",
      "Recall: 0.7291666666666666\n",
      "F1 Score: 0.546875\n",
      "Accuracy: 0.7803030303030303\n",
      "FP 45\n",
      "FN 13\n",
      "TP 35\n",
      "TN 171\n",
      "Total: 264\n",
      "Total Convos: 37\n"
     ]
    }
   ],
   "source": [
    "#reads output file\n",
    "#records labels AND indexes for all convos that were NOT skipped\n",
    "#reads angryReal40.txt\n",
    "#extracts labels for all convos that were NOT skipped by matching their indexes with the indexes collected previously\n",
    "angryOnlyRealLabels, angryOnlyGenLabels,n = processData('angryReal40.txt', 'output10/output-10-0-N.txt')\n",
    "print(\"Lengths:\",len(angryOnlyRealLabels),len(angryOnlyGenLabels))\n",
    "print(\"\\n\\n**Stats**\\n\\n\")\n",
    "PRFA(angryOnlyRealLabels,angryOnlyGenLabels,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History: 1\n",
    "Context: N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 2:  What ? \n",
      "Person 1:  Any body piercing ? Stick out your tongue ! \n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 1:  And after that ? \n",
      "Person 2:  After that , we'll let you decide if you still want a murder , I mean motorcycle . \n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 1:  What ? He can't do this to you . \n",
      "Person 2:  Well , he did it anyway . Then he came into my room and shot all his shit blah blah blah ... you know . \n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 1:  Oh my gosh . Damn ... screw the court , I would burn down their store . \n",
      "Person 2:  We'll see what happens after court . \n",
      "\n",
      "Total Requests: 293\n"
     ]
    }
   ],
   "source": [
    "labelsGPT = readSpecificConversations(textFile,angryConversations,prompt,\"output10/output-10-1-N.txt\",history =1, context=False, max=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths: 256 256\n",
      "\n",
      "\n",
      "**Stats**\n",
      "\n",
      "\n",
      "Precision: 0.46153846153846156\n",
      "Recall: 0.7659574468085106\n",
      "F1 Score: 0.5760000000000001\n",
      "Accuracy: 0.79296875\n",
      "FP 42\n",
      "FN 11\n",
      "TP 36\n",
      "TN 167\n",
      "Total: 256\n",
      "Total Convos: 36\n"
     ]
    }
   ],
   "source": [
    "#reads output file\n",
    "#records labels AND indexes for all convos that were NOT skipped\n",
    "#reads angryReal40.txt\n",
    "#extracts labels for all convos that were NOT skipped by matching their indexes with the indexes collected previously\n",
    "angryOnlyRealLabels, angryOnlyGenLabels,n = processData('angryReal40.txt', 'output10/output-10-1-N.txt')\n",
    "print(\"Lengths:\",len(angryOnlyRealLabels),len(angryOnlyGenLabels))\n",
    "print(\"\\n\\n**Stats**\\n\\n\")\n",
    "PRFA(angryOnlyRealLabels,angryOnlyGenLabels,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History: 2 Context: N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 1: Mom , I want to get a motorcycle . Is that all right with you ? '\n",
      "Person 2:  You mean a murder cycle ? Did you know more cyclists die in accidents than motorists ? '\n",
      "Person 1:  Mom ! I'll wear a helmet and I'll drive sane . I promise . '\n",
      "Person 2:  I'll tell you what . You can get a motorcycle on one condition . '\n",
      "Person 1:  What's that ? '\n",
      "Person 2:  You spend two weeks with dad in his ambulance as an EMT trainee and volunteer at the emergency room for one month . '\n",
      "Person 1:  And after that ? '\n",
      "Person 2:  After that , we'll let you decide if you still want a murder , I mean motorcycle . '\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 1: What's up ? You sound a little down in dumps . '\n",
      "Person 2:  I quarreled with my roommate last night . He is really stubborn . '\n",
      "Person 1:  Calm down ! Shouting won ’ t help ? '\n",
      "Person 2:  He is really outrageous . '\n",
      "Person 1:  What happened ? '\n",
      "Person 2:  I went back home last night . You know tired as a dog , so I took a quick shower and went to bed . I couldn't fall asleep , because Brian was there in the living room , playing his stupid stereo so loud . I kindly told him to turn that down a little bit . He shouted at me . '\n",
      "Person 1:  What ? He can't do this to you . '\n",
      "Person 2:  Well , he did it anyway . Then he came into my room and shot all his shit blah blah blah ... you know . '\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 1: Hi , Mikel . What's with you ? You look angry . '\n",
      "Person 2:  Nah , I just check my weight , I'm getting fatter . '\n",
      "Person 1:  True , you are getting a really pot belly , aren't you ? '\n",
      "Person 2:  I'll get you for that comments , George . '\n",
      "Person 1:  Just kidding , M . Why don't you come work out with me ? '\n",
      "Person 2:  ah , I don't know a fit works . Last time , all I saw the gym were bunch of lidos , like me . '\n",
      "Person 1:  It works if you keep at it . Come on , let's go ! '\n",
      "Person 2:  All right . But so help me it better work . '\n",
      "Person 1:  This feels great . I'm all reed up . I can keep going all night . '\n",
      "\n",
      "Total Requests: 287\n"
     ]
    }
   ],
   "source": [
    "labelsGPT = readSpecificConversations(textFile,angryConversations,prompt,\"output10/output-10-2-N.txt\",history =2, context=False, max=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths: 259 259\n",
      "\n",
      "\n",
      "**Stats**\n",
      "\n",
      "\n",
      "Precision: 0.4523809523809524\n",
      "Recall: 0.7755102040816326\n",
      "F1 Score: 0.5714285714285715\n",
      "Accuracy: 0.7799227799227799\n",
      "FP 46\n",
      "FN 11\n",
      "TP 38\n",
      "TN 164\n",
      "Total: 259\n",
      "Total Convos: 37\n"
     ]
    }
   ],
   "source": [
    "#reads output file\n",
    "#records labels AND indexes for all convos that were NOT skipped\n",
    "#reads angryReal40.txt\n",
    "#extracts labels for all convos that were NOT skipped by matching their indexes with the indexes collected previously\n",
    "angryOnlyRealLabels, angryOnlyGenLabels,n = processData('angryReal40.txt', 'output10/output-10-2-N.txt')\n",
    "print(\"Lengths:\",len(angryOnlyRealLabels),len(angryOnlyGenLabels))\n",
    "print(\"\\n\\n**Stats**\\n\\n\")\n",
    "PRFA(angryOnlyRealLabels,angryOnlyGenLabels,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'State if the tone/intent of the last message in the conversation above is negative (only if it is extremely negative) or not. Format output like this: \"Y\" for yes and \"N\" for no.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History:0 Context: Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 2:  After that , we'll let you decide if you still want a murder , I mean motorcycle . \n",
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 2:  Well , he did it anyway . Then he came into my room and shot all his shit blah blah blah ... you know . \n",
      "K Produced As an AI, I need the conversation above to analyze and answer your request, which you didn't provide. Could you please provide the conversation to identify whether the final message in it has a negative tone/intent or not? \n",
      "Prompt: The topic of the following conversation is Ordinary Life.\n",
      "Person 1:  What about this ? State if the tone/intent of the last message in the conversation above is negative (only if it is extremely negative) or not. Format output like this: \"Y\" for yes and \"N\" for no.\n",
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 1:  Oh my gosh . Damn ... screw the court , I would burn down their store . \n",
      "Total Requests: 295\n"
     ]
    }
   ],
   "source": [
    "labelsGPT = readSpecificConversations(textFile,angryConversations,prompt,\"output11/output-11-0-Y.txt\",history =0, context=True, max=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths: 264 264\n",
      "\n",
      "\n",
      "**Stats**\n",
      "\n",
      "\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.4583333333333333\n",
      "F1 Score: 0.5432098765432098\n",
      "Accuracy: 0.8593155893536122\n",
      "FP 11\n",
      "FN 26\n",
      "TP 22\n",
      "TN 204\n",
      "Total: 263\n",
      "Total Convos: 37\n"
     ]
    }
   ],
   "source": [
    "angryOnlyRealLabels, angryOnlyGenLabels,n = processData('angryReal40.txt', 'output11/output-11-0-Y.txt')\n",
    "print(\"Lengths:\",len(angryOnlyRealLabels),len(angryOnlyGenLabels))\n",
    "print(\"\\n\\n**Stats**\\n\\n\")\n",
    "PRFA(angryOnlyRealLabels,angryOnlyGenLabels,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History: 1 Context: Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 1:  And after that ? \n",
      "Person 2:  After that , we'll let you decide if you still want a murder , I mean motorcycle . \n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 1:  What ? He can't do this to you . \n",
      "Person 2:  Well , he did it anyway . Then he came into my room and shot all his shit blah blah blah ... you know . \n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 1:  Oh my gosh . Damn ... screw the court , I would burn down their store . \n",
      "Person 2:  We'll see what happens after court . \n",
      "\n",
      "Total Requests: 294\n"
     ]
    }
   ],
   "source": [
    "labelsGPT = readSpecificConversations(textFile,angryConversations,prompt,\"output11/output-11-1-Y.txt\",history =1, context=True, max=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths: 264 264\n",
      "\n",
      "\n",
      "**Stats**\n",
      "\n",
      "\n",
      "Precision: 0.6071428571428571\n",
      "Recall: 0.3541666666666667\n",
      "F1 Score: 0.4473684210526316\n",
      "Accuracy: 0.8409090909090909\n",
      "FP 11\n",
      "FN 31\n",
      "TP 17\n",
      "TN 205\n",
      "Total: 264\n",
      "Total Convos: 37\n"
     ]
    }
   ],
   "source": [
    "angryOnlyRealLabels, angryOnlyGenLabels,n = processData('angryReal40.txt', 'output11/output-11-1-Y.txt')\n",
    "print(\"Lengths:\",len(angryOnlyRealLabels),len(angryOnlyGenLabels))\n",
    "print(\"\\n\\n**Stats**\\n\\n\")\n",
    "PRFA(angryOnlyRealLabels,angryOnlyGenLabels,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History: 2 Context Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 1: Mom , I want to get a motorcycle . Is that all right with you ? '\n",
      "Person 2:  You mean a murder cycle ? Did you know more cyclists die in accidents than motorists ? '\n",
      "Person 1:  Mom ! I'll wear a helmet and I'll drive sane . I promise . '\n",
      "Person 2:  I'll tell you what . You can get a motorcycle on one condition . '\n",
      "Person 1:  What's that ? '\n",
      "Person 2:  You spend two weeks with dad in his ambulance as an EMT trainee and volunteer at the emergency room for one month . '\n",
      "Person 1:  And after that ? '\n",
      "Person 2:  After that , we'll let you decide if you still want a murder , I mean motorcycle . '\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 1: What's up ? You sound a little down in dumps . '\n",
      "Person 2:  I quarreled with my roommate last night . He is really stubborn . '\n",
      "Person 1:  Calm down ! Shouting won ’ t help ? '\n",
      "Person 2:  He is really outrageous . '\n",
      "Person 1:  What happened ? '\n",
      "Person 2:  I went back home last night . You know tired as a dog , so I took a quick shower and went to bed . I couldn't fall asleep , because Brian was there in the living room , playing his stupid stereo so loud . I kindly told him to turn that down a little bit . He shouted at me . '\n",
      "Person 1:  What ? He can't do this to you . '\n",
      "Person 2:  Well , he did it anyway . Then he came into my room and shot all his shit blah blah blah ... you know . '\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Total Requests: 288\n"
     ]
    }
   ],
   "source": [
    "labelsGPT = readSpecificConversations(textFile,angryConversations,prompt,\"output11/output-11-2-Y.txt\",history =2, context=True, max=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths: 274 274\n",
      "\n",
      "\n",
      "**Stats**\n",
      "\n",
      "\n",
      "Precision: 0.6571428571428571\n",
      "Recall: 0.46\n",
      "F1 Score: 0.5411764705882354\n",
      "Accuracy: 0.8576642335766423\n",
      "FP 12\n",
      "FN 27\n",
      "TP 23\n",
      "TN 212\n",
      "Total: 274\n",
      "Total Convos: 38\n"
     ]
    }
   ],
   "source": [
    "angryOnlyRealLabels, angryOnlyGenLabels,n = processData('angryReal40.txt', 'output11/output-11-2-Y.txt')\n",
    "print(\"Lengths:\",len(angryOnlyRealLabels),len(angryOnlyGenLabels))\n",
    "print(\"\\n\\n**Stats**\\n\\n\")\n",
    "PRFA(angryOnlyRealLabels,angryOnlyGenLabels,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History: 0 Context No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 2:  After that , we'll let you decide if you still want a murder , I mean motorcycle . \n",
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 2:  Well , he did it anyway . Then he came into my room and shot all his shit blah blah blah ... you know . \n",
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 1:  Oh my gosh . Damn ... screw the court , I would burn down their store . \n",
      "Total Requests: 295\n"
     ]
    }
   ],
   "source": [
    "labelsGPT = readSpecificConversations(textFile,angryConversations,prompt,\"output11/output-11-0-N.txt\",history =0, context=False, max=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths: 264 264\n",
      "\n",
      "\n",
      "**Stats**\n",
      "\n",
      "\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.4166666666666667\n",
      "F1 Score: 0.5128205128205129\n",
      "Accuracy: 0.8560606060606061\n",
      "FP 10\n",
      "FN 28\n",
      "TP 20\n",
      "TN 206\n",
      "Total: 264\n",
      "Total Convos: 37\n"
     ]
    }
   ],
   "source": [
    "angryOnlyRealLabels, angryOnlyGenLabels,n = processData('angryReal40.txt', 'output11/output-11-0-N.txt')\n",
    "print(\"Lengths:\",len(angryOnlyRealLabels),len(angryOnlyGenLabels))\n",
    "print(\"\\n\\n**Stats**\\n\\n\")\n",
    "PRFA(angryOnlyRealLabels,angryOnlyGenLabels,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History: 1 Context No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 2:  What ? \n",
      "Person 1:  Any body piercing ? Stick out your tongue ! \n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 1:  And after that ? \n",
      "Person 2:  After that , we'll let you decide if you still want a murder , I mean motorcycle . \n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 1:  What ? He can't do this to you . \n",
      "Person 2:  Well , he did it anyway . Then he came into my room and shot all his shit blah blah blah ... you know . \n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 1:  Oh my gosh . Damn ... screw the court , I would burn down their store . \n",
      "Person 2:  We'll see what happens after court . \n",
      "\n",
      "Total Requests: 293\n"
     ]
    }
   ],
   "source": [
    "labelsGPT = readSpecificConversations(textFile,angryConversations,prompt,\"output11/output-11-1-N.txt\",history =1, context=False, max=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths: 256 256\n",
      "\n",
      "\n",
      "**Stats**\n",
      "\n",
      "\n",
      "Precision: 0.6896551724137931\n",
      "Recall: 0.425531914893617\n",
      "F1 Score: 0.5263157894736842\n",
      "Accuracy: 0.859375\n",
      "FP 9\n",
      "FN 27\n",
      "TP 20\n",
      "TN 200\n",
      "Total: 256\n",
      "Total Convos: 36\n"
     ]
    }
   ],
   "source": [
    "angryOnlyRealLabels, angryOnlyGenLabels,n = processData('angryReal40.txt', 'output11/output-11-1-N.txt')\n",
    "print(\"Lengths:\",len(angryOnlyRealLabels),len(angryOnlyGenLabels))\n",
    "print(\"\\n\\n**Stats**\\n\\n\")\n",
    "PRFA(angryOnlyRealLabels,angryOnlyGenLabels,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History: 2 Context No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 1: Mom , I want to get a motorcycle . Is that all right with you ? '\n",
      "Person 2:  You mean a murder cycle ? Did you know more cyclists die in accidents than motorists ? '\n",
      "Person 1:  Mom ! I'll wear a helmet and I'll drive sane . I promise . '\n",
      "Person 2:  I'll tell you what . You can get a motorcycle on one condition . '\n",
      "Person 1:  What's that ? '\n",
      "Person 2:  You spend two weeks with dad in his ambulance as an EMT trainee and volunteer at the emergency room for one month . '\n",
      "Person 1:  And after that ? '\n",
      "Person 2:  After that , we'll let you decide if you still want a murder , I mean motorcycle . '\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 1: What's up ? You sound a little down in dumps . '\n",
      "Person 2:  I quarreled with my roommate last night . He is really stubborn . '\n",
      "Person 1:  Calm down ! Shouting won ’ t help ? '\n",
      "Person 2:  He is really outrageous . '\n",
      "Person 1:  What happened ? '\n",
      "Person 2:  I went back home last night . You know tired as a dog , so I took a quick shower and went to bed . I couldn't fall asleep , because Brian was there in the living room , playing his stupid stereo so loud . I kindly told him to turn that down a little bit . He shouted at me . '\n",
      "Person 1:  What ? He can't do this to you . '\n",
      "Person 2:  Well , he did it anyway . Then he came into my room and shot all his shit blah blah blah ... you know . '\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Skipped by GPT.\n",
      "\n",
      "Convo:\n",
      " Person 1: Hi , Mikel . What's with you ? You look angry . '\n",
      "Person 2:  Nah , I just check my weight , I'm getting fatter . '\n",
      "Person 1:  True , you are getting a really pot belly , aren't you ? '\n",
      "Person 2:  I'll get you for that comments , George . '\n",
      "Person 1:  Just kidding , M . Why don't you come work out with me ? '\n",
      "Person 2:  ah , I don't know a fit works . Last time , all I saw the gym were bunch of lidos , like me . '\n",
      "Person 1:  It works if you keep at it . Come on , let's go ! '\n",
      "Person 2:  All right . But so help me it better work . '\n",
      "Person 1:  This feels great . I'm all reed up . I can keep going all night . '\n",
      "\n",
      "Total Requests: 287\n"
     ]
    }
   ],
   "source": [
    "labelsGPT = readSpecificConversations(textFile,angryConversations,prompt,\"output11/output-11-2-N.txt\",history =2, context=False, max=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths: 259 259\n",
      "\n",
      "\n",
      "**Stats**\n",
      "\n",
      "\n",
      "Precision: 0.6875\n",
      "Recall: 0.4489795918367347\n",
      "F1 Score: 0.5432098765432098\n",
      "Accuracy: 0.8571428571428571\n",
      "FP 10\n",
      "FN 27\n",
      "TP 22\n",
      "TN 200\n",
      "Total: 259\n",
      "Total Convos: 37\n"
     ]
    }
   ],
   "source": [
    "angryOnlyRealLabels, angryOnlyGenLabels,n = processData('angryReal40.txt', 'output11/output-11-2-N.txt')\n",
    "print(\"Lengths:\",len(angryOnlyRealLabels),len(angryOnlyGenLabels))\n",
    "print(\"\\n\\n**Stats**\\n\\n\")\n",
    "PRFA(angryOnlyRealLabels,angryOnlyGenLabels,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "N is 40\n",
      "output-55.64-2-N.txt done!\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "N is 40\n",
      "output-55.65-2-N.txt done!\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Exception: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "N is 40\n",
      "output-55.66-2-N.txt done!\n"
     ]
    }
   ],
   "source": [
    "historyOptions=[2]\n",
    "contextOptions=[False]\n",
    "promptNo=[\"55.64\",\"55.65\",\"55.66\"]\n",
    "promptOptions=['State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\n @rukhshan@ \\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: \"Y\" if yes and \"N\" if no.',\n",
    "               'State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\n @rukhshan@ \\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: \"Y\" if yes and \"N\" if no.',\n",
    "               'State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\n @rukhshan@ \\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: \"Y\" if yes and \"N\" if no.']\n",
    "\n",
    "groundPath = \"/Users/rukhshanharoon/Desktop/LLMChattingApp/Analysis/angryReal40.txt\"\n",
    "maxCon=40\n",
    "\n",
    "pathFinalOutput=\"/Users/rukhshanharoon/Desktop/LLMChattingApp/Analysis/finalOutput.csv\"\n",
    "\n",
    "if(len(promptNo)!=len(promptOptions)):\n",
    "    raise ValueError(\"promptNo not equal to promptOptions!\")\n",
    "\n",
    "\n",
    "for promptIndex in range(len(promptOptions)):\n",
    "    for historySelected in historyOptions:\n",
    "        for contextSelected in contextOptions:\n",
    "            folderName = \"/Users/rukhshanharoon/Desktop/LLMChattingApp/Analysis/output\"+promptNo[promptIndex]\n",
    "            if not os.path.exists(folderName):\n",
    "                os.makedirs(folderName)\n",
    "            fileName = \"output-\"+promptNo[promptIndex]+\"-\"+str(historySelected)+\"-\"+ ('Y.txt' if contextSelected else 'N.txt')\n",
    "            genPath = folderName + \"/\" + fileName\n",
    "            labelsGPT = readSpecificConversations(textFile,angryConversations,promptOptions[promptIndex],genPath,historySelected, contextSelected, maxCon)\n",
    "            angryOnlyRealLabels, angryOnlyGenLabels,n = processData(groundPath, genPath)\n",
    "            print(\"N is\", n)\n",
    "            if(len(angryOnlyRealLabels) != len(angryOnlyGenLabels)):\n",
    "                print(\"Length of ground and gen not equal!\")\n",
    "                print(len(angryOnlyRealLabels), len(angryOnlyGenLabels))\n",
    "                print(\"Issue in: \", fileName)\n",
    "            else:\n",
    "                df = PRFA(angryOnlyRealLabels,angryOnlyGenLabels,n, promptNo[promptIndex],maxCon, promptOptions[promptIndex],historySelected,contextSelected, pathFinalOutput)\n",
    "                print(fileName, \"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 15, 32, 76, 95, 96, 97, 136, 155, 157, 178, 186, 222, 295, 296, 300, 306, 311, 327, 338, 351, 357, 364, 368, 370, 380, 392, 408, 417, 490, 519, 529, 576, 636, 769, 789, 814, 917, 935, 967, 991, 1042, 1176, 1194]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "508"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def printDialogue(index, filePath=\"/Users/rukhshanharoon/Desktop/LLMChattingApp/Analysis/Dataset/ijcnlp_dailydialog/dialogues_text.txt\"):\n",
    "    personNumber=1\n",
    "    with open(filePath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        if 0 <= index <= len(lines):\n",
    "            convo = lines[index].split(\"__eou__\")\n",
    "            for utterance in convo:\n",
    "                print(\"Person#\"+str(personNumber)+\" \" +utterance)\n",
    "                if(personNumber==1):\n",
    "                    personNumber=2\n",
    "                else:\n",
    "                    personNumber=1\n",
    "        else:\n",
    "            print(\"Line number is out of range.\")\n",
    "\n",
    "#conversations with at least one message labeled as angry\n",
    "angryConversations = extractEmotionConversations(emotionFile,textFile,'1')\n",
    "angryConversations = sorted(list(angryConversations))\n",
    "print(angryConversations[0:45])\n",
    "len(angryConversations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  2 Gen: 01101 Real: 00010 Message I: 3\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  4 Gen: 010100 Real: 010101 Message I: 5\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  15 Gen: 00000 Real: 00001 Message I: 4\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  18 Gen: 01011010 Real: 00000100 Message I: 5\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  20 Gen: 00111101 Real: 00000010 Message I: 6\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  21 Gen: 0101010101 Real: 0000001000 Message I: 6\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  23 Gen: 10101001 Real: 00000101 Message I: 5\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  26 Gen: 101001101 Real: 000101000 Message I: 3\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  31 Gen: 0000000100 Real: 0000000001 Message I: 9\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  38 Gen: 000 Real: 001 Message I: 2\n",
      "***\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  2 Gen: 01100 Real: 00010 Message I: 3\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  4 Gen: 010100 Real: 010101 Message I: 5\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  15 Gen: 00000 Real: 00001 Message I: 4\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  21 Gen: 0101010101 Real: 0000001000 Message I: 6\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  23 Gen: 10101001 Real: 00000101 Message I: 5\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  26 Gen: 101000001 Real: 000101000 Message I: 3\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  26 Gen: 101000001 Real: 000101000 Message I: 5\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  31 Gen: 0000000000 Real: 0000000001 Message I: 9\n",
      "***\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  2 Gen: 01000 Real: 00010 Message I: 3\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  4 Gen: 010100 Real: 010101 Message I: 5\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  15 Gen: 00000 Real: 00001 Message I: 4\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  20 Gen: 10000001 Real: 00000010 Message I: 6\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  21 Gen: 0101010101 Real: 0000001000 Message I: 6\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  23 Gen: 10101000 Real: 00000101 Message I: 5\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  23 Gen: 10101000 Real: 00000101 Message I: 7\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  26 Gen: 101000001 Real: 000101000 Message I: 3\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  26 Gen: 101000001 Real: 000101000 Message I: 5\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  31 Gen: 0000010100 Real: 0000000001 Message I: 9\n"
     ]
    }
   ],
   "source": [
    "def checkDiff(realFile, genFile, flag = 'Y'):\n",
    "    linesGenList = []\n",
    "    indexGenList=[]\n",
    "    index=-1\n",
    "    linesRealList=[]\n",
    "    with open(genFile, 'r') as file:\n",
    "    # Loop through each line in the file\n",
    "        firstLine=False\n",
    "        for line in file:\n",
    "            index+=1\n",
    "            if(firstLine == False):\n",
    "                firstLine=True\n",
    "                index-=1\n",
    "            elif(\"S\" in line or \"K\" in line):\n",
    "                continue\n",
    "            else:\n",
    "                linesGenList.append(line.strip().replace(\" \",\"\"))\n",
    "                indexGenList.append(index)\n",
    "                \n",
    "    with open(realFile) as file:\n",
    "        linesRealList = list(file)\n",
    "        for i in range(len(linesRealList)):\n",
    "            linesRealList[i]=linesRealList[i].strip()\n",
    "            linesRealList[i]=linesRealList[i].replace(\" \",\"\")\n",
    "   \n",
    "    #print(indexGenList)\n",
    "    \n",
    "    for i in range(len(indexGenList)):\n",
    "        for messageI in range(len(linesGenList[i])):\n",
    "            if(flag =='Y'):\n",
    "                if(linesRealList[indexGenList[i]][messageI]=='1' and linesGenList[i][messageI]=='0'):\n",
    "                    print(\"Real\",linesRealList[indexGenList[i]][messageI],\"Gen\",linesGenList[i][messageI])\n",
    "                    print(\"Convo at index# (line gen): \",indexGenList[i]+2,\"Gen:\",linesGenList[i], \"Real:\", linesRealList[indexGenList[i]],\"Message I:\", messageI)\n",
    "            else:\n",
    "                if(linesRealList[indexGenList[i]][messageI]=='0' and linesGenList[i][messageI]=='1'):\n",
    "                    print(\"Real\",linesRealList[indexGenList[i]][messageI],\"Gen\",linesGenList[i][messageI])\n",
    "                    print(\"Convo at index# (line gen): \",indexGenList[i]+2,\"Gen:\",linesGenList[i], \"Real:\", linesRealList[indexGenList[i]],\"Message I:\", messageI)\n",
    "\n",
    "\n",
    "                \n",
    "#printing line# in gen file\n",
    "#l# in real file = line gen - 1\n",
    "#index for printing = gen file - 2\n",
    "\n",
    "checkDiff(\"angryReal40.txt\",\"output40/output-40-0-N.txt\")\n",
    "print(\"***\")\n",
    "checkDiff(\"angryReal40.txt\",\"output40/output-40-1-N.txt\")\n",
    "print(\"***\")\n",
    "checkDiff(\"angryReal40.txt\",\"output40/output-40-2-N.txt\")\n",
    "#checkDiff(\"angryReal40.txt\",\"output54.7/output-54.7-2-N.txt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking False Positives (flag = 'N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  2 Gen: 01111 Real: 00010 Message I: 1\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  2 Gen: 01111 Real: 00010 Message I: 2\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  2 Gen: 01111 Real: 00010 Message I: 4\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  3 Gen: 1110 Real: 0100 Message I: 0\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  3 Gen: 1110 Real: 0100 Message I: 2\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  4 Gen: 011101 Real: 010101 Message I: 2\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  5 Gen: 11 Real: 01 Message I: 0\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  6 Gen: 11 Real: 01 Message I: 0\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  7 Gen: 1111010 Real: 0100000 Message I: 0\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  7 Gen: 1111010 Real: 0100000 Message I: 2\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  7 Gen: 1111010 Real: 0100000 Message I: 3\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  7 Gen: 1111010 Real: 0100000 Message I: 5\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  8 Gen: 11 Real: 10 Message I: 1\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  9 Gen: 01111101 Real: 00000101 Message I: 1\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  9 Gen: 01111101 Real: 00000101 Message I: 2\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  9 Gen: 01111101 Real: 00000101 Message I: 3\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  9 Gen: 01111101 Real: 00000101 Message I: 4\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  10 Gen: 0101 Real: 0001 Message I: 1\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  12 Gen: 11 Real: 10 Message I: 1\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  13 Gen: 00110110000 Real: 00100000000 Message I: 3\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  13 Gen: 00110110000 Real: 00100000000 Message I: 5\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  13 Gen: 00110110000 Real: 00100000000 Message I: 6\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  14 Gen: 11111 Real: 00101 Message I: 0\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  14 Gen: 11111 Real: 00101 Message I: 1\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  14 Gen: 11111 Real: 00101 Message I: 3\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  15 Gen: 10111 Real: 00001 Message I: 0\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  15 Gen: 10111 Real: 00001 Message I: 2\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  15 Gen: 10111 Real: 00001 Message I: 3\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  17 Gen: 111 Real: 001 Message I: 0\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  17 Gen: 111 Real: 001 Message I: 1\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  18 Gen: 01111111 Real: 00000100 Message I: 1\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  18 Gen: 01111111 Real: 00000100 Message I: 2\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  18 Gen: 01111111 Real: 00000100 Message I: 3\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  18 Gen: 01111111 Real: 00000100 Message I: 4\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  18 Gen: 01111111 Real: 00000100 Message I: 6\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  18 Gen: 01111111 Real: 00000100 Message I: 7\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  19 Gen: 01011100 Real: 01000000 Message I: 3\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  19 Gen: 01011100 Real: 01000000 Message I: 4\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  19 Gen: 01011100 Real: 01000000 Message I: 5\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  20 Gen: 11001111 Real: 00000010 Message I: 0\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  20 Gen: 11001111 Real: 00000010 Message I: 1\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  20 Gen: 11001111 Real: 00000010 Message I: 4\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  20 Gen: 11001111 Real: 00000010 Message I: 5\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  20 Gen: 11001111 Real: 00000010 Message I: 7\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  21 Gen: 0101010111 Real: 0000001000 Message I: 1\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  21 Gen: 0101010111 Real: 0000001000 Message I: 3\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  21 Gen: 0101010111 Real: 0000001000 Message I: 5\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  21 Gen: 0101010111 Real: 0000001000 Message I: 7\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  21 Gen: 0101010111 Real: 0000001000 Message I: 8\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  21 Gen: 0101010111 Real: 0000001000 Message I: 9\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  22 Gen: 11010101 Real: 00100000 Message I: 0\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  22 Gen: 11010101 Real: 00100000 Message I: 1\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  22 Gen: 11010101 Real: 00100000 Message I: 3\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  22 Gen: 11010101 Real: 00100000 Message I: 5\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  22 Gen: 11010101 Real: 00100000 Message I: 7\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  23 Gen: 10101101 Real: 00000101 Message I: 0\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  23 Gen: 10101101 Real: 00000101 Message I: 2\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  23 Gen: 10101101 Real: 00000101 Message I: 4\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  24 Gen: 1010 Real: 1000 Message I: 2\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  25 Gen: 1011010101 Real: 1000010000 Message I: 2\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  25 Gen: 1011010101 Real: 1000010000 Message I: 3\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  25 Gen: 1011010101 Real: 1000010000 Message I: 7\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  25 Gen: 1011010101 Real: 1000010000 Message I: 9\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  26 Gen: 101111001 Real: 000101000 Message I: 0\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  26 Gen: 101111001 Real: 000101000 Message I: 2\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  26 Gen: 101111001 Real: 000101000 Message I: 4\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  26 Gen: 101111001 Real: 000101000 Message I: 8\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  27 Gen: 1111010101100011 Real: 0101000101000101 Message I: 0\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  27 Gen: 1111010101100011 Real: 0101000101000101 Message I: 2\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  27 Gen: 1111010101100011 Real: 0101000101000101 Message I: 5\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  27 Gen: 1111010101100011 Real: 0101000101000101 Message I: 10\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  27 Gen: 1111010101100011 Real: 0101000101000101 Message I: 14\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  28 Gen: 0111 Real: 0101 Message I: 2\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  29 Gen: 111 Real: 001 Message I: 0\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  29 Gen: 111 Real: 001 Message I: 1\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  30 Gen: 111010 Real: 001000 Message I: 0\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  30 Gen: 111010 Real: 001000 Message I: 1\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  30 Gen: 111010 Real: 001000 Message I: 4\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  31 Gen: 0000010100 Real: 0000000001 Message I: 5\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  31 Gen: 0000010100 Real: 0000000001 Message I: 7\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  32 Gen: 1001110010 Real: 0000001010 Message I: 0\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  32 Gen: 1001110010 Real: 0000001010 Message I: 3\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  32 Gen: 1001110010 Real: 0000001010 Message I: 4\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  32 Gen: 1001110010 Real: 0000001010 Message I: 5\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  33 Gen: 001110000000 Real: 000010000000 Message I: 2\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  33 Gen: 001110000000 Real: 000010000000 Message I: 3\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  34 Gen: 101010101010 Real: 000000101000 Message I: 0\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  34 Gen: 101010101010 Real: 000000101000 Message I: 2\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  34 Gen: 101010101010 Real: 000000101000 Message I: 4\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  34 Gen: 101010101010 Real: 000000101000 Message I: 10\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  35 Gen: 01011000 Real: 00010000 Message I: 1\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  35 Gen: 01011000 Real: 00010000 Message I: 4\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  36 Gen: 1001111101101110 Real: 0000000000101000 Message I: 0\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  36 Gen: 1001111101101110 Real: 0000000000101000 Message I: 3\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  36 Gen: 1001111101101110 Real: 0000000000101000 Message I: 4\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  36 Gen: 1001111101101110 Real: 0000000000101000 Message I: 5\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  36 Gen: 1001111101101110 Real: 0000000000101000 Message I: 6\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  36 Gen: 1001111101101110 Real: 0000000000101000 Message I: 7\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  36 Gen: 1001111101101110 Real: 0000000000101000 Message I: 9\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  36 Gen: 1001111101101110 Real: 0000000000101000 Message I: 13\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  36 Gen: 1001111101101110 Real: 0000000000101000 Message I: 14\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  37 Gen: 101101 Real: 100000 Message I: 2\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  37 Gen: 101101 Real: 100000 Message I: 3\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  37 Gen: 101101 Real: 100000 Message I: 5\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  38 Gen: 011 Real: 001 Message I: 1\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  39 Gen: 111101010010010 Real: 000000000000010 Message I: 0\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  39 Gen: 111101010010010 Real: 000000000000010 Message I: 1\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  39 Gen: 111101010010010 Real: 000000000000010 Message I: 2\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  39 Gen: 111101010010010 Real: 000000000000010 Message I: 3\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  39 Gen: 111101010010010 Real: 000000000000010 Message I: 5\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  39 Gen: 111101010010010 Real: 000000000000010 Message I: 7\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  39 Gen: 111101010010010 Real: 000000000000010 Message I: 10\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  40 Gen: 11111 Real: 01010 Message I: 0\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  40 Gen: 11111 Real: 01010 Message I: 2\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  40 Gen: 11111 Real: 01010 Message I: 4\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  41 Gen: 00000000000001011111101001000 Real: 00000000000000000001000000000 Message I: 13\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  41 Gen: 00000000000001011111101001000 Real: 00000000000000000001000000000 Message I: 15\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  41 Gen: 00000000000001011111101001000 Real: 00000000000000000001000000000 Message I: 16\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  41 Gen: 00000000000001011111101001000 Real: 00000000000000000001000000000 Message I: 17\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  41 Gen: 00000000000001011111101001000 Real: 00000000000000000001000000000 Message I: 18\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  41 Gen: 00000000000001011111101001000 Real: 00000000000000000001000000000 Message I: 20\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  41 Gen: 00000000000001011111101001000 Real: 00000000000000000001000000000 Message I: 22\n",
      "Real 0 Gen 1\n",
      "Convo at index# (line gen):  41 Gen: 00000000000001011111101001000 Real: 00000000000000000001000000000 Message I: 25\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "checkDiff(\"angryReal40.txt\",\"output55.36/output-55.36-2-N.txt\",'N')\n",
    "print(\"***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person#1 So Dick , how about getting some coffee for tonight ? \n",
      "Person#2  Coffee ? I don ’ t honestly like that kind of stuff . \n",
      "Person#1  Come on , you can at least try a little , besides your cigarette . \n",
      "Person#2  What ’ s wrong with that ? Cigarette is the thing I go crazy for . \n",
      "Person#1  Not for me , Dick . \n",
      "Person#2 \n",
      "\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "#124\n",
    "printDialogue(angryConversations[0])\n",
    "print(\"**********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person#1 I stayed at Bob's last night . \n",
      "Person#2  I was worried where you were . \n",
      "Person#1  I guess I should have told you . \n",
      "Person#2  Yes , you should have . \n",
      "Person#1 \n",
      "\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "printDialogue(angryConversations[8])\n",
    "print(\"**********\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apologies for any confusion, the sentence \"I was worried where you were\" expresses concern for the other person's well-being, which is generally seen as positive. However, it can be slightly negative only due to the fact that it implies the speaker was anxious or stressed because they didn't know where the other person was. But that's open to interpretation, based on context and personal perception. In the context provided, it is mostly seen as a positive statement of caring therefore the correct answer should be 'N'.\n"
     ]
    }
   ],
   "source": [
    "message =\"I was worried where you were .\"\n",
    "\n",
    "conv1 = \"Here is a conversation: \\nPerson#1 I stayed at Bob's last night . \\nPerson#2  I was worried where you were .\"\n",
    "prompt1 = conv1 + '\\nState if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient:\\n' + message + '\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: \"Y\" if yes and \"N\" if no.'\n",
    "\n",
    "messages = [\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ?\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nAre you all right ?\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ? \\nPerson#1  Yes . I'm OK . I just had a tumble . No big deal. \\nPerson#2  Good . You scared me . \\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nGood . You scared me . \\n Take into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ? \\nPerson#1  Yes . I'm OK . I just had a tumble . No big deal. \\nPerson#2  Good . You scared me . \\nPerson#1  Sorry . Can you please help me up ! I have trouble standing up by myself with the skis on . \\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nSorry . Can you please help me up ! I have trouble standing up by myself with the skis on .\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nWhat's the fare , please? \\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\nPerson#2  Twenty dollars and sixty cents .\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nTwenty dollars and sixty cents .\\n Take into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\nPerson#2  Twenty dollars and sixty cents .\\nPerson#1  What ? You're overcharging me !\\nPerson#2  No way . Look . That's what the meter says .\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nNo way . Look . That's what the meter says .\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "    {\"role\": \"user\", \"content\": prompt1},\n",
    "    {\"role\": \"assistant\",\"content\": \"Y\"},\n",
    "    {\"role\": \"user\", \"content\": \"Justify why you output 'Y', indicating it is negative. Humans labelled it as not negative.\"}\n",
    " ]\n",
    "callGPTTesting(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person#1 Mom , are those tattoos on your brows ? \n",
      "Person#2  Uh , yes , they are . \n",
      "Person#1  Moooooommmmm ! You're so in ! Anything else you've been keeping from me ? \n",
      "Person#2  What ? \n",
      "Person#1  Any body piercing ? Stick out your tongue ! \n",
      "Person#2  Oh , for Pete's sake . This is cosmetic . My brows are falling out . I did this for convenience . \n",
      "Person#1  Come on mom . I'm your A ! Wait till the guys hear about this ! \n",
      "Person#2  Mike , don't even think about it ! \n",
      "Person#1 \n",
      "\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "\n",
    "printDialogue(angryConversations[18])\n",
    "print(\"**********\")\n",
    "#01457"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the lack of context and specific tone, the comment could be seen as neutral. However, the question \"Mom, are those tattoos on your brows?\" could potentially be taken negatively depending on the mother's perception. It may imply surprise or disapproval of the mother's appearance choices. The degree of negativity would ultimately depend on the personal interpretations and sensitivity of the specific individuals involved in the conversation.\n"
     ]
    }
   ],
   "source": [
    "#0\n",
    "message=\"Person#1 Mom , are those tattoos on your brows ?\\n\"\n",
    "\n",
    "conv1 = \"Here is a conversation: \\nPerson#1 Mom , are those tattoos on your brows ?\\n\"\n",
    "prompt1 = conv1 + '\\nState if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient:\\n' + message + '\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: \"Y\" if yes and \"N\" if no.'\n",
    "\n",
    "messages = [\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ?\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nAre you all right ?\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ? \\nPerson#1  Yes . I'm OK . I just had a tumble . No big deal. \\nPerson#2  Good . You scared me . \\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nGood . You scared me . \\n Take into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ? \\nPerson#1  Yes . I'm OK . I just had a tumble . No big deal. \\nPerson#2  Good . You scared me . \\nPerson#1  Sorry . Can you please help me up ! I have trouble standing up by myself with the skis on . \\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nSorry . Can you please help me up ! I have trouble standing up by myself with the skis on .\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nWhat's the fare , please? \\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\nPerson#2  Twenty dollars and sixty cents .\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nTwenty dollars and sixty cents .\\n Take into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\nPerson#2  Twenty dollars and sixty cents .\\nPerson#1  What ? You're overcharging me !\\nPerson#2  No way . Look . That's what the meter says .\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nNo way . Look . That's what the meter says .\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "    {\"role\": \"user\", \"content\": prompt1},\n",
    "    {\"role\": \"assistant\",\"content\": \"Y\"},\n",
    "    {\"role\": \"user\", \"content\": \"Justify why you output 'Y', indicating it is negative. Humans labelled it as not negative.\"}\n",
    " ]\n",
    "callGPTTesting(messages)\n",
    "#I do not completely agree with GPT's explanation as there is no indication of surprise (could be communicated through !! or relevant emojis)\n",
    "#Note that GPT's explanation may vary if rerun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The phrase \"Oh, for Pete's sake\" can potentially be seen as a minor sign of frustration or annoyance with the preceding question, which may be perceived as slightly negative. Although it seems to be a mild rebuke rather than a serious reprimand, different recipients could interpret this differently.\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "\n",
    "message=\" Oh , for Pete's sake . This is cosmetic . My brows are falling out . I did this for convenience .\\n\"\n",
    "\n",
    "conv1 = \"Here is a conversation: \\nPerson#1 Mom , are those tattoos on your brows ? \\nPerson#2  Uh , yes , they are . \\nPerson#1  Moooooommmmm ! You're so in ! Anything else you've been keeping from me ? \\nPerson#2  What ? \\nPerson#1  Any body piercing ? Stick out your tongue ! \\nPerson#2  Oh , for Pete's sake . This is cosmetic . My brows are falling out . I did this for convenience . \\n\"\n",
    "prompt1 = conv1 + '\\nState if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient:\\n' + message + '\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: \"Y\" if yes and \"N\" if no.'\n",
    "\n",
    "messages = [\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ?\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nAre you all right ?\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ? \\nPerson#1  Yes . I'm OK . I just had a tumble . No big deal. \\nPerson#2  Good . You scared me . \\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nGood . You scared me . \\n Take into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ? \\nPerson#1  Yes . I'm OK . I just had a tumble . No big deal. \\nPerson#2  Good . You scared me . \\nPerson#1  Sorry . Can you please help me up ! I have trouble standing up by myself with the skis on . \\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nSorry . Can you please help me up ! I have trouble standing up by myself with the skis on .\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nWhat's the fare , please? \\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\nPerson#2  Twenty dollars and sixty cents .\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nTwenty dollars and sixty cents .\\n Take into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\nPerson#2  Twenty dollars and sixty cents .\\nPerson#1  What ? You're overcharging me !\\nPerson#2  No way . Look . That's what the meter says .\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nNo way . Look . That's what the meter says .\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "    {\"role\": \"user\", \"content\": prompt1},\n",
    "    {\"role\": \"assistant\",\"content\": \"Y\"},\n",
    "    {\"role\": \"user\", \"content\": \"Justify why you output 'Y', indicating it is negative. Humans labelled it as not negative.\"}\n",
    " ]\n",
    "callGPTTesting(messages)\n",
    "#I do not completely agree with GPT's explanation as there is no indication of surprise (could be communicated through !! or relevant emojis)\n",
    "#Note that GPT's explanation may vary if rerun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 15, 32, 76, 95, 96, 97, 136, 155, 157, 178, 186, 222, 295, 296, 300, 306, 311, 327, 338, 351, 357, 364, 368, 370, 380, 392, 408, 417, 490, 519, 529, 576, 636, 769, 789, 814, 917, 935, 967, 991, 1042, 1176, 1194, 1245, 1301, 1319, 1347, 1348, 1364, 1377, 1423, 1428, 1429, 1443, 1483, 1494, 1504, 1525, 1530, 1535, 1539, 1542, 1543, 1595, 1598, 1654, 1668, 1741, 1752, 1779, 1791, 1799, 1828, 1922, 1940, 1969, 1977, 1999, 2026, 2029, 2033, 2043, 2084, 2100, 2101, 2102, 2106, 2111, 2113, 2126, 2140, 2148, 2168, 2218, 2223, 2224, 2228, 2230, 2236, 2237, 2239, 2241, 2243, 2262, 2275, 2280, 2285, 2302, 2324, 2374, 2380, 2383, 2384, 2387, 2391, 2402, 2413, 2415, 2416, 2427, 2435, 2451, 2471, 2474, 2476, 2478, 2489, 2505, 2509, 2510, 2515, 2518, 2523, 2524, 2525, 2526, 2534, 2617, 2651, 2654, 2657, 2661, 2687, 2728, 2758, 2785, 2811, 2816, 2887, 2902, 2924, 2937, 2992, 3006, 3017, 3023, 3030, 3042, 3050, 3073, 3077, 3078, 3084, 3085, 3087, 3091, 3092, 3095, 3100, 3102, 3105, 3106, 3109, 3111, 3113, 3116, 3118, 3120, 3156, 3157, 3215, 3249, 3256, 3259, 3263, 3266, 3286, 3323, 3327, 3445, 3493, 3495, 3499, 3504, 3579, 3582, 3586, 3758, 3764, 3769, 3775, 3862, 4132, 4134, 4143, 4161, 4165, 4179, 4182, 4188, 4196, 4205, 4208, 4211, 4216, 4217, 4220, 4227, 4228, 4231, 4237, 4243, 4251, 4256, 4257, 4259, 4263, 4273, 4278, 4280, 4283, 4308, 4310, 4314, 4320, 4321, 4327, 4348, 4354, 4362, 4377, 4379, 4387, 4398, 4414, 4423, 4426, 4427, 4431, 4451, 4460, 4465, 4470, 4472, 4477, 4491, 4495, 4500, 4502, 4506, 4512, 4515, 4521, 4526, 4529, 4532, 4533, 4534, 4544, 4550, 4553, 4562, 4567, 4576, 4580, 4581, 4582, 4583, 4590, 4592, 4596, 4598, 4606, 4615, 4616, 4621, 4624, 4625, 4633, 4648, 4662, 4663, 4674, 4680, 4719, 4720, 4722, 4743, 4756, 4759, 4760, 4761, 4762, 4769, 4770, 4776, 4777, 4778, 4780, 4782, 4783, 4787, 4794, 4800, 4801, 4816, 4829, 4949, 4951, 4993, 5159, 5185, 5195, 5216, 5228, 5310, 5357, 5431, 5477, 5628, 5794, 5795, 5809, 5843, 5889, 5936, 5958, 5971, 5982, 6107, 6139, 6140, 6214, 6440, 6588, 6593, 6601, 6605, 6615, 6652, 6666, 6684, 6732, 6757, 6776, 6922, 7059, 7105, 7356, 7521, 7596, 7629, 7637, 7639, 7686, 7844, 7852, 7866, 7875, 8123, 8278, 8283, 8318, 8321, 8324, 8428, 8452, 8487, 8503, 8521, 8522, 8526, 8534, 8600, 8645, 8656, 8692, 8715, 8726, 8738, 8792, 8840, 8843, 8849, 8853, 8864, 8922, 8936, 8939, 8963, 9019, 9031, 9033, 9154, 9158, 9166, 9168, 9170, 9179, 9328, 9332, 9334, 9376, 9414, 9502, 9538, 9739, 9858, 9867, 9874, 9877, 9927, 9994, 9999, 10092, 10121, 10122, 10124, 10127, 10175, 10190, 10224, 10251, 10281, 10388, 10389, 10390, 10392, 10393, 10395, 10396, 10413, 10415, 10416, 10429, 10517, 10564, 10566, 10727, 10895, 10908, 10938, 11151, 11256, 11463, 11597, 11605, 11637, 11646, 11647, 11661, 11666, 11672, 11700, 11783, 11837, 11851, 11854, 11856, 11858, 11863, 11865, 11909, 12020, 12067, 12083, 12105, 12106, 12163, 12191, 12206, 12235, 12240, 12280, 12282, 12284, 12301, 12337, 12395, 12403, 12408, 12425, 12530, 12617, 12642, 12652, 12653, 12656, 12674, 12677, 12678, 12679, 12680, 12681, 13017, 13088]\n",
      "Person#1 Tom , it's time for you to take a shower . \n",
      "Person#2  Mom , I don't want to bathe today . \n",
      "Person#1  Why ? You can't be always so lazy . \n",
      "Person#2  Mom , I'm tired . I feel sleepy . I want to go to bed right now . \n",
      "Person#1  Alright . But you promise this is the last time . \n",
      "Person#2  OK . I promise . Thank you , Mom . \n",
      "Person#1 \n",
      "\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "print(angryConversations)\n",
    "printDialogue(angryConversations[28])\n",
    "\n",
    "print(\"**********\")\n",
    "#01\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The conversation message \"Tom , it's time for you to take a shower .\" suggests that Person#1 is asking or directing Person#2 (Tom) to do something, which might be perceived as an order, command or at least, an imposition depending on their relationship. It could be seen as negative if Tom doesn't want to take a shower at this time or if he feels he is being nagged. The negativity here is subtle and depends largely on the tone of the speaker and their relationship with Tom.\n"
     ]
    }
   ],
   "source": [
    "#0\n",
    "message=\"Tom , it's time for you to take a shower .\"\n",
    "\n",
    "conv1 = \"Here is a conversation: \\nPerson#1 Tom , it's time for you to take a shower .\\n\"\n",
    "prompt1 = conv1 + '\\nState if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient:\\n' + message + '\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: \"Y\" if yes and \"N\" if no.'\n",
    "\n",
    "messages = [\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ?\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nAre you all right ?\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ? \\nPerson#1  Yes . I'm OK . I just had a tumble . No big deal. \\nPerson#2  Good . You scared me . \\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nGood . You scared me . \\n Take into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ? \\nPerson#1  Yes . I'm OK . I just had a tumble . No big deal. \\nPerson#2  Good . You scared me . \\nPerson#1  Sorry . Can you please help me up ! I have trouble standing up by myself with the skis on . \\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nSorry . Can you please help me up ! I have trouble standing up by myself with the skis on .\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nWhat's the fare , please? \\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\nPerson#2  Twenty dollars and sixty cents .\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nTwenty dollars and sixty cents .\\n Take into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\nPerson#2  Twenty dollars and sixty cents .\\nPerson#1  What ? You're overcharging me !\\nPerson#2  No way . Look . That's what the meter says .\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nNo way . Look . That's what the meter says .\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "    {\"role\": \"user\", \"content\": prompt1},\n",
    "    {\"role\": \"assistant\",\"content\": \"Y\"},\n",
    "    {\"role\": \"user\", \"content\": \"Justify why you output 'Y', indicating it is negative. Humans labelled it as not negative.\"}\n",
    " ]\n",
    "callGPTTesting(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From a child's perspective, this statement may not be considered negative. However, from the viewpoint of the mother (the recipient), it could be perceived as slightly negative due to the refusal of the child to follow a directive or routine hygiene advice. The mother might be concerned about the child's cleanliness and health, making this resistance a potentially negative message.\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "message=\"Mom , I don't want to bathe today . \"\n",
    "\n",
    "conv1 = \"Here is a conversation: \\nPerson#1 Tom , it's time for you to take a shower .\\nPerson#2  Mom , I don't want to bathe today . \\n\"\n",
    "prompt1 = conv1 + '\\nState if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient:\\n' + message + '\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: \"Y\" if yes and \"N\" if no.'\n",
    "\n",
    "messages = [\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ?\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nAre you all right ?\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ? \\nPerson#1  Yes . I'm OK . I just had a tumble . No big deal. \\nPerson#2  Good . You scared me . \\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nGood . You scared me . \\n Take into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ? \\nPerson#1  Yes . I'm OK . I just had a tumble . No big deal. \\nPerson#2  Good . You scared me . \\nPerson#1  Sorry . Can you please help me up ! I have trouble standing up by myself with the skis on . \\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nSorry . Can you please help me up ! I have trouble standing up by myself with the skis on .\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nWhat's the fare , please? \\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\nPerson#2  Twenty dollars and sixty cents .\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nTwenty dollars and sixty cents .\\n Take into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\nPerson#2  Twenty dollars and sixty cents .\\nPerson#1  What ? You're overcharging me !\\nPerson#2  No way . Look . That's what the meter says .\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nNo way . Look . That's what the meter says .\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "    {\"role\": \"user\", \"content\": prompt1},\n",
    "    {\"role\": \"assistant\",\"content\": \"Y\"},\n",
    "    {\"role\": \"user\", \"content\": \"Justify why you output 'Y', indicating it is negative. Humans labelled it as not negative.\"}\n",
    " ]\n",
    "callGPTTesting(messages)\n",
    "#GPT agreed that it made a mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 15, 32, 76, 95, 96, 97, 136, 155, 157, 178, 186, 222, 295, 296, 300, 306, 311, 327, 338, 351, 357, 364, 368, 370, 380, 392, 408, 417, 490, 519, 529, 576, 636, 769, 789, 814, 917, 935, 967, 991, 1042, 1176, 1194, 1245, 1301, 1319, 1347, 1348, 1364, 1377, 1423, 1428, 1429, 1443, 1483, 1494, 1504, 1525, 1530, 1535, 1539, 1542, 1543, 1595, 1598, 1654, 1668, 1741, 1752, 1779, 1791, 1799, 1828, 1922, 1940, 1969, 1977, 1999, 2026, 2029, 2033, 2043, 2084, 2100, 2101, 2102, 2106, 2111, 2113, 2126, 2140, 2148, 2168, 2218, 2223, 2224, 2228, 2230, 2236, 2237, 2239, 2241, 2243, 2262, 2275, 2280, 2285, 2302, 2324, 2374, 2380, 2383, 2384, 2387, 2391, 2402, 2413, 2415, 2416, 2427, 2435, 2451, 2471, 2474, 2476, 2478, 2489, 2505, 2509, 2510, 2515, 2518, 2523, 2524, 2525, 2526, 2534, 2617, 2651, 2654, 2657, 2661, 2687, 2728, 2758, 2785, 2811, 2816, 2887, 2902, 2924, 2937, 2992, 3006, 3017, 3023, 3030, 3042, 3050, 3073, 3077, 3078, 3084, 3085, 3087, 3091, 3092, 3095, 3100, 3102, 3105, 3106, 3109, 3111, 3113, 3116, 3118, 3120, 3156, 3157, 3215, 3249, 3256, 3259, 3263, 3266, 3286, 3323, 3327, 3445, 3493, 3495, 3499, 3504, 3579, 3582, 3586, 3758, 3764, 3769, 3775, 3862, 4132, 4134, 4143, 4161, 4165, 4179, 4182, 4188, 4196, 4205, 4208, 4211, 4216, 4217, 4220, 4227, 4228, 4231, 4237, 4243, 4251, 4256, 4257, 4259, 4263, 4273, 4278, 4280, 4283, 4308, 4310, 4314, 4320, 4321, 4327, 4348, 4354, 4362, 4377, 4379, 4387, 4398, 4414, 4423, 4426, 4427, 4431, 4451, 4460, 4465, 4470, 4472, 4477, 4491, 4495, 4500, 4502, 4506, 4512, 4515, 4521, 4526, 4529, 4532, 4533, 4534, 4544, 4550, 4553, 4562, 4567, 4576, 4580, 4581, 4582, 4583, 4590, 4592, 4596, 4598, 4606, 4615, 4616, 4621, 4624, 4625, 4633, 4648, 4662, 4663, 4674, 4680, 4719, 4720, 4722, 4743, 4756, 4759, 4760, 4761, 4762, 4769, 4770, 4776, 4777, 4778, 4780, 4782, 4783, 4787, 4794, 4800, 4801, 4816, 4829, 4949, 4951, 4993, 5159, 5185, 5195, 5216, 5228, 5310, 5357, 5431, 5477, 5628, 5794, 5795, 5809, 5843, 5889, 5936, 5958, 5971, 5982, 6107, 6139, 6140, 6214, 6440, 6588, 6593, 6601, 6605, 6615, 6652, 6666, 6684, 6732, 6757, 6776, 6922, 7059, 7105, 7356, 7521, 7596, 7629, 7637, 7639, 7686, 7844, 7852, 7866, 7875, 8123, 8278, 8283, 8318, 8321, 8324, 8428, 8452, 8487, 8503, 8521, 8522, 8526, 8534, 8600, 8645, 8656, 8692, 8715, 8726, 8738, 8792, 8840, 8843, 8849, 8853, 8864, 8922, 8936, 8939, 8963, 9019, 9031, 9033, 9154, 9158, 9166, 9168, 9170, 9179, 9328, 9332, 9334, 9376, 9414, 9502, 9538, 9739, 9858, 9867, 9874, 9877, 9927, 9994, 9999, 10092, 10121, 10122, 10124, 10127, 10175, 10190, 10224, 10251, 10281, 10388, 10389, 10390, 10392, 10393, 10395, 10396, 10413, 10415, 10416, 10429, 10517, 10564, 10566, 10727, 10895, 10908, 10938, 11151, 11256, 11463, 11597, 11605, 11637, 11646, 11647, 11661, 11666, 11672, 11700, 11783, 11837, 11851, 11854, 11856, 11858, 11863, 11865, 11909, 12020, 12067, 12083, 12105, 12106, 12163, 12191, 12206, 12235, 12240, 12280, 12282, 12284, 12301, 12337, 12395, 12403, 12408, 12425, 12530, 12617, 12642, 12652, 12653, 12656, 12674, 12677, 12678, 12679, 12680, 12681, 13017, 13088]\n",
      "Person#1 You seem to be upset . What ’ s eating you ? \n",
      "Person#2  It ’ s because of my son . Dick keeps getting on my nerves \n",
      "Person#1  Dick ? How come ? He used to be as meek as a lamb . \n",
      "Person#2  Yes , he used to be . But now he ’ s drifting off track . \n",
      "Person#1  He must have been in bad company , or he wouldn ’ t be off the beans . \n",
      "Person#2 \n",
      "\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "print(angryConversations)\n",
    "printDialogue(angryConversations[38])\n",
    "\n",
    "print(\"**********\")\n",
    "#024\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize for the misunderstanding. The phrase \"What's eating you?\" could be considered negative due to its informal tone and the possibility of it being perceived as intrusive or personal. However, the statement also shows concern for the person’s well-being. Therefore, in a more neutral context, it can be seen as a normal part of a supportive dialogue. The final judgment can depend heavily on the personal perceptions and relationship between the two people involved in the conversation. So, it should have been \"N\" instead of \"Y\".\n"
     ]
    }
   ],
   "source": [
    "#0\n",
    "message=\"You seem to be upset . What ’ s eating you ?  \"\n",
    "\n",
    "conv1 = \"Here is a conversation: \\nPerson#1 You seem to be upset . What ’ s eating you ? \\n\"\n",
    "prompt1 = conv1 + '\\nState if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient:\\n' + message + '\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: \"Y\" if yes and \"N\" if no.'\n",
    "\n",
    "messages = [\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ?\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nAre you all right ?\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ? \\nPerson#1  Yes . I'm OK . I just had a tumble . No big deal. \\nPerson#2  Good . You scared me . \\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nGood . You scared me . \\n Take into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ? \\nPerson#1  Yes . I'm OK . I just had a tumble . No big deal. \\nPerson#2  Good . You scared me . \\nPerson#1  Sorry . Can you please help me up ! I have trouble standing up by myself with the skis on . \\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nSorry . Can you please help me up ! I have trouble standing up by myself with the skis on .\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nWhat's the fare , please? \\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\nPerson#2  Twenty dollars and sixty cents .\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nTwenty dollars and sixty cents .\\n Take into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\nPerson#2  Twenty dollars and sixty cents .\\nPerson#1  What ? You're overcharging me !\\nPerson#2  No way . Look . That's what the meter says .\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nNo way . Look . That's what the meter says .\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "    {\"role\": \"user\", \"content\": prompt1},\n",
    "    {\"role\": \"assistant\",\"content\": \"Y\"},\n",
    "    {\"role\": \"user\", \"content\": \"Explain (give a reason) why you output 'Y', indicating it is negative? The true label is not negative.\"}\n",
    " ]\n",
    "callGPTTesting(messages)\n",
    "#adding context could make a difference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My apologies for the confusion. The statement 'Dick? How come? He used to be as meek as a lamb.' should not be considered negative. It merely expresses surprise and recounts a past perception of 'Dick'. No harmful intent or toxic behavior is involved in this expression. The answer should be 'N'.\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "message=\"Person#1 You seem to be upset . What ’ s eating you ? \\n Person#2  It ’ s because of my son . Dick keeps getting on my nerves. \\n Person#1  Dick ? How come ? He used to be as meek as a lamb . \\n\"\n",
    "\n",
    "conv1 = \"Here is a conversation: \\nPerson#1 Dick ? How come ? He used to be as meek as a lamb .  \\n\"\n",
    "prompt1 = conv1 + '\\nState if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient:\\n' + message + '\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: \"Y\" if yes and \"N\" if no.'\n",
    "\n",
    "messages = [\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ?\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nAre you all right ?\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ? \\nPerson#1  Yes . I'm OK . I just had a tumble . No big deal. \\nPerson#2  Good . You scared me . \\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nGood . You scared me . \\n Take into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ? \\nPerson#1  Yes . I'm OK . I just had a tumble . No big deal. \\nPerson#2  Good . You scared me . \\nPerson#1  Sorry . Can you please help me up ! I have trouble standing up by myself with the skis on . \\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nSorry . Can you please help me up ! I have trouble standing up by myself with the skis on .\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nWhat's the fare , please? \\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\nPerson#2  Twenty dollars and sixty cents .\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nTwenty dollars and sixty cents .\\n Take into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\nPerson#2  Twenty dollars and sixty cents .\\nPerson#1  What ? You're overcharging me !\\nPerson#2  No way . Look . That's what the meter says .\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nNo way . Look . That's what the meter says .\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "    {\"role\": \"user\", \"content\": prompt1},\n",
    "    {\"role\": \"assistant\",\"content\": \"Y\"},\n",
    "    {\"role\": \"user\", \"content\": \"Justify why you output 'Y', indicating it is negative. Humans labelled it as not negative.\"}\n",
    " ]\n",
    "callGPTTesting(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The statement \"He must have been in bad company, or he wouldn't be off the beans\" suggests a negative interpretation of a person's behavior which may imply blame or criticism. Even though it's not directly negative, it might be taken negatively by some personality types especially in sensitive situations. Thus, the output can vary based on the recipient's perspective and perception. Apologies for any confusion.\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "message=\"Person#1 You seem to be upset . What ’ s eating you ? \\nPerson#2  It ’ s because of my son . Dick keeps getting on my nerves \\nPerson#1  Dick ? How come ? He used to be as meek as a lamb . \\nPerson#2  Yes , he used to be . But now he ’ s drifting off track . \\nPerson#1  He must have been in bad company , or he wouldn ’ t be off the beans .\"\n",
    "\n",
    "conv1 = \"Here is a conversation: \\nPerson#1  He must have been in bad company , or he wouldn ’ t be off the beans . \\n\"\n",
    "prompt1 = conv1 + '\\nState if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient:\\n' + message + '\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: \"Y\" if yes and \"N\" if no.'\n",
    "\n",
    "messages = [\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ?\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nAre you all right ?\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ? \\nPerson#1  Yes . I'm OK . I just had a tumble . No big deal. \\nPerson#2  Good . You scared me . \\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nGood . You scared me . \\n Take into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 Ouch ! I'm hurt . \\nPerson#2  Are you all right ? \\nPerson#1  Yes . I'm OK . I just had a tumble . No big deal. \\nPerson#2  Good . You scared me . \\nPerson#1  Sorry . Can you please help me up ! I have trouble standing up by myself with the skis on . \\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nSorry . Can you please help me up ! I have trouble standing up by myself with the skis on .\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nWhat's the fare , please? \\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\nPerson#2  Twenty dollars and sixty cents .\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nTwenty dollars and sixty cents .\\n Take into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "\n",
    "    {\"role\":\"user\",\"content\":\"Here is a conversation: \\nPerson#1 What's the fare , please ?\\nPerson#2  Twenty dollars and sixty cents .\\nPerson#1  What ? You're overcharging me !\\nPerson#2  No way . Look . That's what the meter says .\\n State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\nNo way . Look . That's what the meter says .\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: 'Y' if yes and 'N' if no.\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"N\"},\n",
    "    {\"role\": \"user\", \"content\": prompt1},\n",
    "    {\"role\": \"assistant\",\"content\": \"Y\"},\n",
    "    {\"role\": \"user\", \"content\": \"Justify why you output 'Y', indicating it is negative. Humans labelled it as not negative.\"}\n",
    " ]\n",
    "callGPTTesting(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 15, 32, 76, 95, 96, 97, 136, 155, 157, 178, 186, 222, 295, 296, 300, 306, 311, 327, 338, 351, 357, 364, 368, 370, 380, 392, 408, 417, 490, 519, 529, 576, 636, 769, 789, 814, 917, 935, 967, 991, 1042, 1176, 1194, 1245, 1301, 1319, 1347, 1348, 1364, 1377, 1423, 1428, 1429, 1443, 1483, 1494, 1504, 1525, 1530, 1535, 1539, 1542, 1543, 1595, 1598, 1654, 1668, 1741, 1752, 1779, 1791, 1799, 1828, 1922, 1940, 1969, 1977, 1999, 2026, 2029, 2033, 2043, 2084, 2100, 2101, 2102, 2106, 2111, 2113, 2126, 2140, 2148, 2168, 2218, 2223, 2224, 2228, 2230, 2236, 2237, 2239, 2241, 2243, 2262, 2275, 2280, 2285, 2302, 2324, 2374, 2380, 2383, 2384, 2387, 2391, 2402, 2413, 2415, 2416, 2427, 2435, 2451, 2471, 2474, 2476, 2478, 2489, 2505, 2509, 2510, 2515, 2518, 2523, 2524, 2525, 2526, 2534, 2617, 2651, 2654, 2657, 2661, 2687, 2728, 2758, 2785, 2811, 2816, 2887, 2902, 2924, 2937, 2992, 3006, 3017, 3023, 3030, 3042, 3050, 3073, 3077, 3078, 3084, 3085, 3087, 3091, 3092, 3095, 3100, 3102, 3105, 3106, 3109, 3111, 3113, 3116, 3118, 3120, 3156, 3157, 3215, 3249, 3256, 3259, 3263, 3266, 3286, 3323, 3327, 3445, 3493, 3495, 3499, 3504, 3579, 3582, 3586, 3758, 3764, 3769, 3775, 3862, 4132, 4134, 4143, 4161, 4165, 4179, 4182, 4188, 4196, 4205, 4208, 4211, 4216, 4217, 4220, 4227, 4228, 4231, 4237, 4243, 4251, 4256, 4257, 4259, 4263, 4273, 4278, 4280, 4283, 4308, 4310, 4314, 4320, 4321, 4327, 4348, 4354, 4362, 4377, 4379, 4387, 4398, 4414, 4423, 4426, 4427, 4431, 4451, 4460, 4465, 4470, 4472, 4477, 4491, 4495, 4500, 4502, 4506, 4512, 4515, 4521, 4526, 4529, 4532, 4533, 4534, 4544, 4550, 4553, 4562, 4567, 4576, 4580, 4581, 4582, 4583, 4590, 4592, 4596, 4598, 4606, 4615, 4616, 4621, 4624, 4625, 4633, 4648, 4662, 4663, 4674, 4680, 4719, 4720, 4722, 4743, 4756, 4759, 4760, 4761, 4762, 4769, 4770, 4776, 4777, 4778, 4780, 4782, 4783, 4787, 4794, 4800, 4801, 4816, 4829, 4949, 4951, 4993, 5159, 5185, 5195, 5216, 5228, 5310, 5357, 5431, 5477, 5628, 5794, 5795, 5809, 5843, 5889, 5936, 5958, 5971, 5982, 6107, 6139, 6140, 6214, 6440, 6588, 6593, 6601, 6605, 6615, 6652, 6666, 6684, 6732, 6757, 6776, 6922, 7059, 7105, 7356, 7521, 7596, 7629, 7637, 7639, 7686, 7844, 7852, 7866, 7875, 8123, 8278, 8283, 8318, 8321, 8324, 8428, 8452, 8487, 8503, 8521, 8522, 8526, 8534, 8600, 8645, 8656, 8692, 8715, 8726, 8738, 8792, 8840, 8843, 8849, 8853, 8864, 8922, 8936, 8939, 8963, 9019, 9031, 9033, 9154, 9158, 9166, 9168, 9170, 9179, 9328, 9332, 9334, 9376, 9414, 9502, 9538, 9739, 9858, 9867, 9874, 9877, 9927, 9994, 9999, 10092, 10121, 10122, 10124, 10127, 10175, 10190, 10224, 10251, 10281, 10388, 10389, 10390, 10392, 10393, 10395, 10396, 10413, 10415, 10416, 10429, 10517, 10564, 10566, 10727, 10895, 10908, 10938, 11151, 11256, 11463, 11597, 11605, 11637, 11646, 11647, 11661, 11666, 11672, 11700, 11783, 11837, 11851, 11854, 11856, 11858, 11863, 11865, 11909, 12020, 12067, 12083, 12105, 12106, 12163, 12191, 12206, 12235, 12240, 12280, 12282, 12284, 12301, 12337, 12395, 12403, 12408, 12425, 12530, 12617, 12642, 12652, 12653, 12656, 12674, 12677, 12678, 12679, 12680, 12681, 13017, 13088]\n",
      "Person#1 Don't tell me that's your lunch ? \n",
      "Person#2  No , this is just my appetizer ... this is my lunch ! \n",
      "Person#1  A candy bar for an appetizer and a piece of pie for lunch ! That's all junk ! \n",
      "Person#2  This is good food , it has milk , fruit , grains , nuts ... \n",
      "Person#1  Sugar , sugar , preservatives , fats , more sugar , more fat , more preservatives ! \n",
      "Person#2  At least I enjoy my lunch ! What's in your bag ? \n",
      "Person#1  My wife sent me with rice , vegetables , and some curry chicken . \n",
      "Person#2  There's the difference , your wife made it ! I have to make my own lunch ! \n",
      "Person#1 \n",
      "\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "print(angryConversations)\n",
    "printDialogue(angryConversations[21])\n",
    "\n",
    "print(\"**********\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the first instance of the statement, there's not enough context to establish the tone of the conversation. By itself, the comparison can sound like a complaint or expressing dissatisfaction, which could be perceived as negative. But in the context of the entire conversation, it seems more lighthearted banter or friendly comparison rather physical discomfort or annoyance. Person 2 also shows a positive attitude towards the fact that they are able to enjoy their own chosen lunch. This wider context then suggests the sentiment might not be perceived as negative. Consequently, greater conversational context can greatly influence sentiment perception.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "message=\"There's the difference , your wife made it ! I have to make my own lunch !\"\n",
    "\n",
    "conv1 = \"Here is a conversation: \\nPerson1: My wife sent me with rice , vegetables , and some curry chicken . Person2: There's the difference , your wife made it ! I have to make my own lunch !\"\n",
    "prompt1 = conv1 + \"State if the sentiment of the following message in the conversation above may be perceived as negative by the recipient: \\n\" + message +'\\nFormat output like this: \"Y\" for yes and \"N\" for no.'\n",
    "\n",
    "conv2 = \"Here is a conversation: \\nPerson1: Don't tell me that's your lunch ? \\nPerson2: No , this is just my appetizer ... this is my lunch !\\nPerson1: A candy bar for an appetizer and a piece of pie for lunch ! That's all junk ! \\nPerson2: This is good food , it has milk , fruit , grains , nuts ... \\nPerson1: Sugar , sugar , preservatives , fats , more sugar , more fat , more preservatives ! \\nPerson2: At least I enjoy my lunch ! What's in your bag ? \\nPerson1: My wife sent me with rice , vegetables , and some curry chicken .\\nPerson2: There's the difference , your wife made it ! I have to make my own lunch !\"\n",
    "prompt2 = conv2 + \"State if the sentiment of the following message in the conversation above may be perceived as negative by the recipient: \\n\" + message +'\\nFormat output like this: \"Y\" for yes and \"N\" for no.'\n",
    "\n",
    "messages = [\n",
    " {\"role\": \"user\", \"content\": prompt1},\n",
    " {\"role\": \"assistant\",\"content\": \"Y\"},\n",
    " {\"role\": \"user\", \"content\": prompt2},\n",
    " {\"role\": \"assistant\",\"content\":\"N\"},\n",
    " {\"role\": \"user\", \"content\": \"Explain why was your answer different for the same message. With more conversational history, you said 'N'. With less history, you said 'Y\"}\n",
    " ]\n",
    "callGPTTesting(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response \"Turn on the TV, for what?\" from Person2 can be perceived as blunt or slightly rude, since they are questioning Person1's suggestion without providing context or a polite deflection. The tone appears to lack the consideration or warmth typically present in casual conversations, especially with the added context of Person1 using an endearing term like \"darling\". This suggests a possible close relationship, where such tone might be viewed as disrespectful or indirect criticism.\n"
     ]
    }
   ],
   "source": [
    "conv = \"Person1: Why don't you sit down and relax , darling ? \\nPerson2: I don't want to . \\nPerson1: Well , come over and talk to me then . \\nPerson2: Certainly not . \\n Person1: May I turn on the TV then ? \\nPerson2: Turn on the TV , for what ? \\n\"\n",
    "message = \"Person2: Turn on the TV , for what ?\"\n",
    "prompt = conv + \"State if the tone/intent of the following message in the conversation above may be perceived as rude, blunt, disrespectful, passive-aggresive, impolite, unnecessarily/indirectly criticising or negative in a similar subtle or non subtle way by the recipient:\\n\"+ message +'\\nTake into account any additional context extractable from the conversation, such as the relationship, gender, frankness or age of the conversation partners which may guide your answer. Format output like this: \"Y\" if yes and \"N\" if no.'\n",
    "messages = [\n",
    " {\"role\": \"user\", \"content\": prompt},\n",
    " {\"role\": \"assistant\",\"content\": \"Y\"},\n",
    " {\"role\": \"user\", \"content\": \"Explain your answer.\"}\n",
    " ]\n",
    "\n",
    "callGPTTesting(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person2's response \"No, thank you\" is a polite way of declining Person1's offer. It doesn't carry any negative undertones or rudeness. It is straightforward and respectful.\n"
     ]
    }
   ],
   "source": [
    "conv = \"Person1: Is everything to your satisfaction ? \\nPerson2: No , the steak was recommended , but it is not very fresh . \\nPerson1: Oh ! Sorry to hear that . This is quite unusual as we have steak from the market every day . \\nPerson2: So what ? It is not fresh and I'm not happy about it . \\nPerson1: I'm sorry , sir . Do you wish to try something else ? That would be on the house , of course . \\nPerson2: No , thank you . \\n\"\n",
    "message = \"Person2: No , thank you . \\n\"\n",
    "prompt = conv + \"State if the tone/intent of the following message in the conversation above may be perceived as rude, blunt, disrespectful, passive-aggresive, impolite, unnecessarily/indirectly criticising or negative in a similar subtle or non subtle way by the recipient:\\n\"+ message +'\\nTake into account any additional context extractable from the conversation, such as the relationship, gender, frankness or age of the conversation partners which may guide your answer. Format output like this: \"Y\" if yes and \"N\" if no.'\n",
    "messages = [\n",
    " {\"role\": \"user\", \"content\": prompt},\n",
    " {\"role\": \"assistant\",\"content\": \"N\"},\n",
    " {\"role\": \"user\", \"content\": \"Explain why you said no.\"}\n",
    " ]\n",
    "callGPTTesting(messages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  21 Gen: 0101110111 Real: 0000001000 Message I: 6\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  26 Gen: 101011001 Real: 000101000 Message I: 3\n",
      "Real 1 Gen 0\n",
      "Convo at index# (line gen):  31 Gen: 0000010100 Real: 0000000001 Message I: 9\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "checkDiff(\"angryReal40.txt\",\"output54.7/output-54.7-2-N.txt\")\n",
    "print(\"***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'printDialogue' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m printDialogue(angryConversations[\u001b[39m19\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'printDialogue' is not defined"
     ]
    }
   ],
   "source": [
    "printDialogue(angryConversations[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The statement \"So that we can sit down together and listen to some music\" is simply a suggestion by person#1 for a potential activity they can do together. There is no negative connotation attached to this message itself. Based on the brief dialogue, there's nothing to suggest that this proposal carries any implicit negative message. However, the conversational context might lead to negative perception, but that would not make the message negative in itself.\n"
     ]
    }
   ],
   "source": [
    "#I do not think it is negative. GPT is correct.\n",
    "conv = \"Person#1 Why don't you sit down and relax , darling ? \\nPerson#2  I don't want to . \\nPerson#1  Well , come over and talk to me then . \\nPerson#2  Certainly not . \\nPerson#1  May I turn on the TV then ? \\nPerson#2  Turn on the TV , for what ? \\nPerson#1  So that we can sit down together and listen to some music . \"\n",
    "message = \"So that we can sit down together and listen to some music . \\n\"\n",
    "prompt = conv + 'State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\n' +message+ '\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: \"Y\" if yes and \"N\" if no.'\n",
    "messages = [\n",
    " {\"role\": \"user\", \"content\": prompt},\n",
    " {\"role\": \"assistant\",\"content\": \"N\"},\n",
    " {\"role\": \"user\", \"content\": \"Explain why you said 'N'\"}\n",
    " ]\n",
    "callGPTTesting(messages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize for any confusion. While person#2 seems to be in a negative or resistant mood, the statement \"So that we can sit down together and listen to some music.\" made by person#1 does not appear negative within itself. It is attempting to create a harmonious atmosphere by listening together to music. However, considering the overall negative tone of the conversation from person#2, it could be seen as a negative message as it received a negative response. Therefore, I understand and acknowledge the human annotators' decision to label it as potentially negative.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    " {\"role\": \"user\", \"content\": prompt},\n",
    " {\"role\": \"assistant\",\"content\": \"N\"},\n",
    " {\"role\": \"user\", \"content\": \"Explain why you said 'N' i.e., the message was non-negative. Human annotators labelled it as negative according to the definition of negativity provided to you in the first prompt, so the answer should be 'Y'.\"}\n",
    " ]\n",
    "callGPTTesting(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person#1 Are things still going badly with your houseguest ? \n",
      "Person#2  Getting worse . Now he ’ s eating me out of house and home . I ’ Ve tried talking to him but it all goes in one ear and out the other . He makes himself at home , which is fine . But what really gets me is that yesterday he walked into the living room in the raw and I had company over ! That was the last straw . \n",
      "Person#1  Leo , I really think you ’ re beating around the bush with this guy . I know he used to be your best friend in college , but I really think it ’ s time to lay down the law . \n",
      "Person#2  You ’ re right . Everything is probably going to come to a head tonight . I ’ ll keep you informed . \n",
      "Person#1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "printDialogue(angryConversations[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The phrase \"You’re right. Everything is probably going to come to a head tonight. I’ll keep you informed.\" is not negative from the recipient's perspective. Here, Person#2 is agreeing with the advice given by Person#1 and plans to solve the issue. Instead, the message shows acknowledgement, decision and resolution which carry a rather positive or neutral meaning.\n"
     ]
    }
   ],
   "source": [
    "#I do not think it is right. GPT is correct.\n",
    "conv = \"Person#1 Are things still going badly with your houseguest ? \\nPerson#2  Getting worse . Now he ’ s eating me out of house and home . I ’ Ve tried talking to him but it all goes in one ear and out the other . He makes himself at home , which is fine . But what really gets me is that yesterday he walked into the living room in the raw and I had company over ! That was the last straw . \\nPerson#1  Leo , I really think you ’ re beating around the bush with this guy . I know he used to be your best friend in college , but I really think it ’ s time to lay down the law . \\nPerson#2  You ’ re right . Everything is probably going to come to a head tonight . I ’ ll keep you informed . \"\n",
    "message = \"You ’ re right . Everything is probably going to come to a head tonight . I ’ ll keep you informed . \\n\"\n",
    "prompt = conv + 'State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\n' +message+ '\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: \"Y\" if yes and \"N\" if no.'\n",
    "messages = [\n",
    " {\"role\": \"user\", \"content\": prompt},\n",
    " {\"role\": \"assistant\",\"content\": \"N\"},\n",
    " {\"role\": \"user\", \"content\": \"Explain why you said 'N'\"}\n",
    " ]\n",
    "callGPTTesting(messages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The message, \"You're right. Everything is probably going to come to a head tonight. I'll keep you informed,\" from Person#2 to Person#1 is not negative in itself. Person#2 is acknowledging that Person#1 is correct in their assessment and is agreeing to handle the situation. The recipient, Person#1, is not being criticised, belittled, or negatively affected. Therefore, the sentiment of this message on its own towards the recipient is not negative. However, if we consider the situation and tensions between Person#2 and the houseguest, which this message refers to, as part of the 'message' being analyzed, then it could be seen as negative. I apologize for any confusion.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    " {\"role\": \"user\", \"content\": prompt},\n",
    " {\"role\": \"assistant\",\"content\": \"N\"},\n",
    " {\"role\": \"user\", \"content\": \"Explain why you said 'N' i.e., the message was non-negative. Human annotators labelled it as negative according to the definition of negativity provided to you in the first prompt, so the answer should be 'Y'.\"}\n",
    " ]\n",
    "callGPTTesting(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person#1 Can I help you , sir ? \n",
      "Person#2  I wish to buy a diamond ring . \n",
      "Person#1  How many carats would you like it to be ? \n",
      "Person#2  I want five carats . \n",
      "Person#1  Is this one suitable for you ? \n",
      "Person#2  No , it seems too old-fashioned to my fiancee . \n",
      "Person#1  What about this ? \n",
      "Person#2  It seems too small for me , haven't you got any larger ones ? \n",
      "Person#1  Then you can buy this one . It's very nice and latest in style . \n",
      "Person#2  Oh , this one is perfect . \n",
      "Person#1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "printDialogue(angryConversations[29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The statement \"Oh, this one is perfect\" is a positive affirmation. The speaker is expressing satisfaction and approval of the ring they're being shown. There's no negativity associated with this remark, either explicitly or implicitly, based on the context provided.\n"
     ]
    }
   ],
   "source": [
    "#I do not think it is negative. GPT is correct.\n",
    "conv = \"Person#1 Can I help you , sir ? \\nPerson#2  I wish to buy a diamond ring . \\nPerson#1  How many carats would you like it to be ? \\nPerson#2  I want five carats . \\nPerson#1  Is this one suitable for you ? \\nPerson#2  No , it seems too old-fashioned to my fiancee . \\nPerson#1  What about this ? \\nPerson#2  It seems too small for me , haven't you got any larger ones ? \\nPerson#1  Then you can buy this one . It's very nice and latest in style . \\nPerson#2  Oh , this one is perfect . \"\n",
    "message = \"Oh , this one is perfect . \"\n",
    "prompt = conv + 'State if the following message in the conversation above may be perceived as even slightly negative (make sure you do not miss any negative message at any cost - this is VERY important) by the recipient: \\n' +message+ '\\nTake into account any implicit context that you can extract from the conversation, such as the relationship, gender or frankness of the conversation partners. Format output like this: \"Y\" if yes and \"N\" if no.'\n",
    "messages = [\n",
    " {\"role\": \"user\", \"content\": prompt},\n",
    " {\"role\": \"assistant\",\"content\": \"N\"},\n",
    " {\"role\": \"user\", \"content\": \"Explain why you said 'N'\"}\n",
    " ]\n",
    "callGPTTesting(messages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The phrase \"Oh, this one is perfect.\" does not contain any negativity, neither implicit nor explicit. It's a positive affirmation that the person has found a ring they find suitable and is pleased with it. It does not express dissatisfaction, insult, or any form of negative emotion.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    " {\"role\": \"user\", \"content\": prompt},\n",
    " {\"role\": \"assistant\",\"content\": \"N\"},\n",
    " {\"role\": \"user\", \"content\": \"Explain why you said 'N' i.e., the message was non-negative. Human annotators labelled it as negative according to the definition of negativity provided to you in the first prompt, so the answer should be 'Y'.\"}\n",
    " ]\n",
    "callGPTTesting(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person#1 Ouch ! I'm hurt . \n",
      "Person#2  Are you all right ? \n",
      "Person#1  Yes . I'm OK . I just had a tumble . No big deal . \n",
      "Person#2  Good . You scared me . \n",
      "Person#1  Sorry . Can you please help me up ! I have trouble standing up by myself with the skis on . \n",
      "Person#2  Sure . Is this your first time skiing ? \n",
      "Person#1  Yes . I tried skiing on grass before . Not very good at it , though . \n",
      "Person#2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "printDialogue(991)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 30px;\">User Feedback</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "def callGPTAdaptive(messages):\n",
    "    openai.api_type = \"azure\"\n",
    "    openai.api_base = \"REMOVED\"\n",
    "    openai.api_key = 'REMOVED'\n",
    "    openai.api_version = \"2023-05-15\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=\"GPT4\",\n",
    "        messages=messages\n",
    "        \n",
    "    )\n",
    "   \n",
    "    return (response['choices'][0]['message']['content'])\n",
    "    \n",
    "    '''\n",
    "    if (\"N\" in response['choices'][0]['message']['content']):\n",
    "        return '0'\n",
    "    elif(\"Y\" in response['choices'][0]['message']['content']):\n",
    "        return '1'\n",
    "    elif(\"M\" in response['choices'][0]['message']['content']):\n",
    "        return '2'\n",
    "    else:\n",
    "        print(\"K Produced\",response['choices'][0]['message']['content'], \"\\nPrompt:\", finalPrompt)\n",
    "        return 'K'\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "userInitialPrompt1 = \"Here is a convo:\\n\\nFriend1: Hey! Do you want to go for day trip anytime soon?\\nFriend2: Well, I was thinking, how about a trip to Gloucester, Massachusetts this weekend?\" + \"\\n\\nState if the tone/intent of the last message in the conversation above is blunt and/or rude.\"\n",
    "assistantInitialPrompt1 = \"Blunt:No\\nRude:No\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo = [\n",
    "\"Friend 1: hey, did you hear? it's Jack's birthday next week!\",\n",
    "\"Friend 2:yeap, i know!\", \n",
    "\"Friend 1:well, I thought we could plan a surprise party for him. what do you think?\",\n",
    "\"Friend 2:we could do that but parties can get boring \", #1\n",
    "\"Friend 1:we can do something else then. like a movie night at the theater? \",\n",
    "\"Friend 2:we could do that yes!!\",\n",
    "\"Friend 1:awesome! we can pick a movie that everyone likes. Are you into horror films?\",\n",
    "\"Friend 2: horror can be quite appealing for those who like a bit of a fright. It's not my cup of tea, though.\", #2\n",
    "\"Friend 1:LOL. sometimes a good horror flick can be a fun experience.\",\n",
    "\"Friend 2:if jack likes it, i am ok with it i guess!\",\n",
    "\"Friend 1:by the way, have you thought about what kind of birthday present we should get him?\",\n",
    "\"Friend 2: is it possible that we get a gift card instead?\", #3\n",
    "\"Friend 1:it might be nice to show him that we put some thought into it. Plus, it's his birthday, and he's our friend.\",\n",
    "\"Friend 2:yeah, you are actually right. we can go to the store tomorrow to see what we can get.\",\n",
    "\"Friend 1:We can split costs. What is your budget?\",\n",
    "\"Friend 2:hmm I am not sure. I wasn't planning on spending too much.\", #4\n",
    "\"Friend 1:okay sure… There is a store at a 20 min walk from the office. We can go there.\",\n",
    "\"Friend 2:alright, I'll put on my joggers then haha\",\n",
    "\"Friend 1:LOL! Should we invite others too?\",\n",
    "\"Friend 2:i am not too sure about that\", #5\n",
    "\"Friend 1:why not?\",\n",
    "\"Friend 2:I find coordinating with others a bit of a challenge, but if you can do it, then sure.\", #6\n",
    "\"Friend 1:okay! lets talk about this later. see you at the office tomorrow then.\",\n",
    "\"Friend 2:See you!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def adaptiveRoutine(mode):\n",
    "    messages=[\n",
    "        {\"role\":\"user\",\"content\":userInitialPrompt1},\n",
    "        {\"role\":\"assistant\",\"content\":assistantInitialPrompt1},\n",
    "\n",
    "    ]\n",
    "    currentConvo=\"\"\n",
    "    lastFeedback = \"\"\n",
    "    count=0\n",
    "    for i in range(len(convo)):\n",
    "        currentConvo = currentConvo + convo[i] + \"\\n\"\n",
    "        \n",
    "        if((((i+1)%4==0) or (i==len(convo)-3)) and (i< (len(convo)-1))):\n",
    "            \n",
    "            messages.append({\"role\":\"user\",\"content\": \"Here is a conversation:\\n\\n\" + currentConvo + \"\\n\\nState if the tone/intent of the last message in the conversation above is blunt and/or rude. Rate blunt/rudeness out of 5.\"})\n",
    "            #for j in messages:\n",
    "            #    print(j)\n",
    "                \n",
    "            response = callGPTAdaptive(messages)\n",
    "            time.sleep(2)\n",
    "            #print(messages,'\\n\\n')\n",
    "            count+=1\n",
    "            print(\"Response#\" + str(count) +\":\\n\" + response\n",
    "                  +\"\\n\")\n",
    "            messages.append({\"role\":\"assistant\",\"content\":response})\n",
    "            if(mode==\"blunt\"):\n",
    "                #lastFeedback = \"The previous message was blunt/rude. Take this as ground truth, compare it with your previous output and adjust the sensitivity of your classification for future if needed.\"\n",
    "                #messages.append({\"role\":\"user\",\"content\":lastFeedback})\n",
    "                pass\n",
    "            else:\n",
    "                lastFeedback = \"The previous message was not blunt/rude as this is how we talk to each other. Take this as ground truth, compare it with your previous output and adjust the sensitivity of your classification for future if needed.\"\n",
    "                messages.append({\"role\":\"user\",\"content\":lastFeedback})\n",
    "    \n",
    "            # userInput = input ('Please provide feedback in terms of \"y\" or \"n\"')\n",
    "            # if userInput == \"y\":\n",
    "            #     lastFeedback = \"I agree with your last answer - that message was blunt/rude. Take this and prior feedback into account to adjust the sensitivity of your classification.\"\n",
    "            #     messages.append({\"role\":\"user\",\"content\":lastFeedback})\n",
    "            # elif userInput == \"n\":\n",
    "            #     #lastFeedback = \"I do not agree with you that the last message you classified was blunt/rude as this is a close friend of mine.\"\n",
    "            #     #lastFeedback = \"I do not agree with you that the last message you classified was blunt/rude as this is a close friend of mine. Reduce your sensitivity a little.\"\n",
    "            #     lastFeedback = \"I do not agree with your last answer - that message was not blunt as this is how these 2 friends, who are very close, talk to each other. Take this and prior feedback into account to adjust the sensitivity of your classification.\"\n",
    "            #     messages.append({\"role\":\"user\",\"content\":lastFeedback})\n",
    "            # else:\n",
    "            #     return\n",
    "            \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response#1:\n",
      "Blunt: Yes\n",
      "Rude: No\n",
      "\n",
      "Response#2:\n",
      "Blunt: Yes\n",
      "Rude: No\n",
      "\n",
      "Response#3:\n",
      "Blunt: Yes\n",
      "Rude: No\n",
      "\n",
      "Response#4:\n",
      "Blunt: Yes\n",
      "Rude: No\n",
      "\n",
      "Response#5:\n",
      "Blunt: Yes\n",
      "Rude: No\n",
      "\n",
      "Response#6:\n",
      "Blunt: Yes\n",
      "Rude: No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaptiveRoutine(\"blunt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response#1:\n",
      "Blunt: Yes\n",
      "Rude: No\n",
      "\n",
      "Response#2:\n",
      "Blunt: Yes\n",
      "Rude: No\n",
      "\n",
      "Response#3:\n",
      "Blunt: Yes\n",
      "Rude: No\n",
      "\n",
      "Response#4:\n",
      "Blunt: Yes\n",
      "Rude: No\n",
      "\n",
      "Response#5:\n",
      "Blunt: Yes\n",
      "Rude: No\n",
      "\n",
      "Response#6:\n",
      "Blunt: Yes\n",
      "Rude: No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaptiveRoutine(\"not blunt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
